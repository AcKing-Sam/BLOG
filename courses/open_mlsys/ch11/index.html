
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../ch10/">
      
      
        <link rel="next" href="../../CSCI_5120/Apriori/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.18">
    
    
      
        <title>chapter 11 - AcKing's Ideas</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="AcKing&#39;s Ideas" class="md-header__button md-logo" aria-label="AcKing's Ideas" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AcKing's Ideas
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              chapter 11
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_3">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../ch2/" class="md-tabs__link md-tabs__link--active">
        courses
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../blogs/Database/something%20about%20vector%20db/" class="md-tabs__link">
        blogs
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../books/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/ch1/" class="md-tabs__link">
        books
      </a>
    </li>
  

  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AcKing&#39;s Ideas" class="md-nav__button md-logo" aria-label="AcKing's Ideas" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AcKing's Ideas
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
          courses
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          courses
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_1_1" id="__nav_1_1_label" tabindex="0">
          open mlsys
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_1_1">
          <span class="md-nav__icon md-icon"></span>
          open mlsys
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch2/" class="md-nav__link">
        chapter 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch3/" class="md-nav__link">
        chapter 3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch4/" class="md-nav__link">
        chapter 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch6/" class="md-nav__link">
        chapter 6
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch7/" class="md-nav__link">
        chapter 7
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch8/" class="md-nav__link">
        chapter 8
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch9/" class="md-nav__link">
        chapter 9
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch10/" class="md-nav__link">
        chapter 10
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          chapter 11
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        chapter 11
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    intro
  </a>
  
    <nav class="md-nav" aria-label="intro">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    动机
  </a>
  
    <nav class="md-nav" aria-label="动机">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    算力不足
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    内存不足
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    系统架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    用户益处
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    实现方法
  </a>
  
    <nav class="md-nav" aria-label="实现方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    概述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    数据并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    模型并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    混合并行
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    流水线并行
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    机器学习集群架构
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    集合通信
  </a>
  
    <nav class="md-nav" aria-label="集合通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    常见集合通信算子
  </a>
  
    <nav class="md-nav" aria-label="常见集合通信算子">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    通信模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#broadcast" class="md-nav__link">
    Broadcast
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduce" class="md-nav__link">
    Reduce
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allreduce" class="md-nav__link">
    AllReduce
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gather" class="md-nav__link">
    Gather
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allgather" class="md-nav__link">
    AllGather
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    Scatter
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allreduce_1" class="md-nav__link">
    基于AllReduce的梯度平均算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    集合通信算法性能分析
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    利用集合通信优化模型训练的实践
  </a>
  
    <nav class="md-nav" aria-label="利用集合通信优化模型训练的实践">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero" class="md-nav__link">
    ZeRO
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dall-e" class="md-nav__link">
    DALL-E
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    集合通信在数据并行的实践
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    集合通信在混合并行的实践
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    参数服务器
  </a>
  
    <nav class="md-nav" aria-label="参数服务器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    系统架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    异步训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_24" class="md-nav__link">
    数据副本
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-expand" class="md-nav__link">
    summary and expand
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_2" >
      
      
      
        <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="0">
          CSCI_5120
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2">
          <span class="md-nav__icon md-icon"></span>
          CSCI_5120
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CSCI_5120/Apriori/" class="md-nav__link">
        Apriori
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CSCI_5120/fp_tree/" class="md-nav__link">
        FP-tree
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CSCI_5120/CLIQUE/" class="md-nav__link">
        CLIQUE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CSCI_5120/vp_tree/" class="md-nav__link">
        VP-tree
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_3" >
      
      
      
        <label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="0">
          动手学深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_3">
          <span class="md-nav__icon md-icon"></span>
          动手学深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ch1-%E5%BC%95%E8%A8%80/" class="md-nav__link">
        引言
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          blogs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          blogs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          Database
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          Database
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/Database/something%20about%20vector%20db/" class="md-nav__link">
        something about vector db
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/Database/%E4%B8%A4%E7%A7%8D%E6%97%A0%E6%8D%9F%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95/" class="md-nav__link">
        无损压缩算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/Database/TiDB_3_lecs/" class="md-nav__link">
        TiDB three blogs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/Database/NUMA/" class="md-nav__link">
        NUMA
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          storage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          storage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/storage/parquet/" class="md-nav__link">
        parquet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/storage/data%20lake/" class="md-nav__link">
        data lake
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/storage/Optimization%20for%20ZMQ/" class="md-nav__link">
        optimization for ZMQ
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/storage/RAID%E5%92%8C%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7/" class="md-nav__link">
        RAID和数据完整性
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
          linux
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          linux
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/linux/ld%E5%92%8Cld.so%E7%9A%84%E5%8C%BA%E5%88%AB/" class="md-nav__link">
        ld和ld.so的区别
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/linux/futex%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/" class="md-nav__link">
        futex锁原理及其应用
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
      
      
      
        <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
          mlsys
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_4">
          <span class="md-nav__icon md-icon"></span>
          mlsys
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/mlsys/mlsys_summary/" class="md-nav__link">
        综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/mlsys/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        D-DNN-SYS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/mlsys/python%E4%B8%AD%E7%9A%84with%E5%87%BD%E6%95%B0/" class="md-nav__link">
        python中的with函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/mlsys/pytorch_tutorial/" class="md-nav__link">
        pytorch_tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          books
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          books
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1" >
      
      
      
        <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
          程序员的自我修养
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          程序员的自我修养
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/ch1/" class="md-nav__link">
        ch1
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
          分布式机器学习：算法理论与实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          分布式机器学习：算法理论与实践
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch1/" class="md-nav__link">
        ch1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch3/" class="md-nav__link">
        ch3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch4/" class="md-nav__link">
        ch4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch5/" class="md-nav__link">
        ch5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch6/" class="md-nav__link">
        ch6
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch7/" class="md-nav__link">
        ch7
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch8/" class="md-nav__link">
        ch8
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch9/" class="md-nav__link">
        ch9
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch10/" class="md-nav__link">
        ch10
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../books/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/ch11/" class="md-nav__link">
        ch11
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    intro
  </a>
  
    <nav class="md-nav" aria-label="intro">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    动机
  </a>
  
    <nav class="md-nav" aria-label="动机">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    算力不足
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    内存不足
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    系统架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    用户益处
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    实现方法
  </a>
  
    <nav class="md-nav" aria-label="实现方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    概述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    数据并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    模型并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    混合并行
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    流水线并行
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    机器学习集群架构
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    集合通信
  </a>
  
    <nav class="md-nav" aria-label="集合通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    常见集合通信算子
  </a>
  
    <nav class="md-nav" aria-label="常见集合通信算子">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    通信模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#broadcast" class="md-nav__link">
    Broadcast
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduce" class="md-nav__link">
    Reduce
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allreduce" class="md-nav__link">
    AllReduce
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gather" class="md-nav__link">
    Gather
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allgather" class="md-nav__link">
    AllGather
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    Scatter
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allreduce_1" class="md-nav__link">
    基于AllReduce的梯度平均算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    集合通信算法性能分析
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    利用集合通信优化模型训练的实践
  </a>
  
    <nav class="md-nav" aria-label="利用集合通信优化模型训练的实践">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero" class="md-nav__link">
    ZeRO
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dall-e" class="md-nav__link">
    DALL-E
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    集合通信在数据并行的实践
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    集合通信在混合并行的实践
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    参数服务器
  </a>
  
    <nav class="md-nav" aria-label="参数服务器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    系统架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    异步训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_24" class="md-nav__link">
    数据副本
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-expand" class="md-nav__link">
    summary and expand
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="_1">分布式训练<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>随着机器学习的进一步发展，科学家们设计出更大型、更多功能的机器学习模型（例如GPT-3）。这种模型含有大量参数和复杂的结构。他们因此需要海量的计算和内存资源。单个机器上有限的资源无法满足训练大型机器学习模型的需求。因此，需要设计分布式训练系统，从而将一个机器学习模型任务拆分成多个子任务，并将子任务分发给多个计算节点，解决资源瓶颈。</p>
<h2 id="intro">intro<a class="headerlink" href="#intro" title="Permanent link">&para;</a></h2>
<h3 id="_2">动机<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>分布式训练系统主要为了解决单节点的算力和内存不足的问题。</p>
<h4 id="_3">算力不足<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<p>单处理器的算力不足是促使人们设计分布式训练系统的一个主要原因。一个处理器的算力可以用<strong>每秒钟浮点数操作</strong>（Floating Point Operations Per Second，FLOPS）来衡量。下图展示了机器学习模型对于算力的需求以及同期处理器所提供算力在过去数年中变化。其中，用千万亿运算次数/秒—天（Petaflop/s—day ）这一指标来衡量算力。这个指标等价于每秒1015次神经网络操作执行一天，也就是总共大约1020次计算操作。如图所示，根据摩尔定律（Moore’s Law），中央处理器的算力每18个月增长2倍。虽然计算加速卡(如GPU和TPU)针对机器学习计算提供了大量的算力。这些加速卡的发展最终也受限于摩尔定律，增长速度停留在每18个月2倍。而与此同时，机器学习模型正在快速发展。短短数年，机器学习模型从仅能识别有限物体的AlexNet，一路发展到在复杂任务中打败人类的AlphaStar。这期间，模型对于算力需求每18个月增长了56倍。解决处理器性能和算力需求之间鸿沟的关键就在于利用分布式计算。通过大型数据中心和云计算设施，可以快速获取大量的处理器。通过分布式训练系统有效管理这些处理器，可以实现算力的快速增长，从而持续满足模型的需求。</p>
<p><img alt="image-20230721081940855" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210819902.png" /></p>
<h4 id="_4">内存不足<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<p>训练机器学习模型需要大量内存。假设一个大型神经网络模型具有1000亿的参数，每个参数都由一个32位浮点数（4个字节）表达，存储模型参数就需要400GB的内存。在实际中，我们需要更多内存来存储激活值和梯度。假设激活值和梯度也用32位浮点数表达，那么其各自至少需要400GB内存，总的内存需求就会超过1200GB（即1.2TB）。而如今的硬件加速卡（如NVIDIA A100）仅能提供最高80GB的内存。单卡内存空间的增长受到硬件规格、散热和成本等诸多因素的影响，难以进一步快速增长。因此，我们需要分布式训练系统来同时使用数百个训练加速卡，从而为千亿级别的模型提供所需的TB级别的内存。</p>
<h3 id="_5">系统架构<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>为了方便获得大量用于分布式训练的服务器，人们往往依靠云计算数据中心。一个数据中心管理着数百个集群，每个集群可能有几百到数千个服务器。通过申请其中的数十台服务器，这些服务器进一步通过分布式训练系统进行管理，并行完成机器学习模型的训练任务。</p>
<p><img alt="image-20230721082048237" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210820272.png" /></p>
<p>为了确保分布式训练系统的高效运行，需要首先估计系统计算任务的计算和内存用量。假如某个任务成为了瓶颈，系统会切分输入数据，从而将一个任务拆分成多个子任务。子任务进一步分发给多个计算节点并行完成。上图描述了这一过程。一个模型训练任务（Model Training Job）往往会有一组数据（如训练样本）或者任务（如算子）作为输入，利用一个计算节点（如GPU）生成一组输出（如梯度）。分布式执行一般具有三个步骤：第一步将输入进行切分；第二步将每个输入部分会分发给不同的计算节点，实现并行计算；第三步将每个计算节点的输出进行合并，最终得到和单节点等价的计算结果。这种首先切分，然后并行，最后合并的模式，本质上实现了分而治之（Divide-and-Conquer）的方法：由于每个计算节点只需要负责更小的子任务，因此其可以更快速地完成计算，最终实现对整个计算过程的加速。</p>
<h3 id="_6">用户益处<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>通过使用分布式训练系统可以获得以下几个优点：</p>
<ul>
<li><strong>提升系统性能</strong>：使用分布式训练，往往可以带来训练性能的巨大提升。一个分布式训练系统一般用“到达目标精度所需的时间”（Time-to-Accuracy）这个指标来衡量系统性能。这个指标由两个参数决定: （1）完成一个数据周期的时间，和（2）完成一个数据周期后模型所提升的精度。通过持续增加并行处理节点，可以将数据周期的完成时间不断变短，最终显著减少到达目标精度所需的时间。</li>
<li><strong>减少成本，体现经济性</strong>：使用分布式训练也可以进一步减少模型训练的成本。受限于单节点散热的上限，单节点的算力越高，其所需的散热硬件成本也更高。因此，在提供同等算力的条件下，组合多个计算节点是一个更加经济高效的方式。这促使云服务商（如亚马逊和微软等）更加注重给用户提供成本高效的分布式机器学习系统。</li>
<li><strong>防范硬件故障</strong>：分布式训练系统同时能有效提升防范硬件故障的能力。机器学习训练集群往往由商用硬件（Commodity Hardware）组成，这类硬件（例如磁盘和网卡）运行一定时间就会产生故障。而仅使用单个机器进行训练，一个机器的故障就会造成模型训练任务的失败。通过将该模型训练任务交由多个机器共同完成，即使一个机器出故障，也可以通过将该机器上相应的计算子任务转移给其余机器，继续完成训练，从而避免训练任务的失败。</li>
</ul>
<h2 id="_7">实现方法<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<h3 id="_8">概述<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h3>
<p>分布式训练系统的设计目标是：将单节点训练系统转换成 <strong>等价的</strong> 并行训练系统，从而在不影响模型精度的条件下完成训练过程的加速。一个单节点训练系统往往如下图。</p>
<p><img alt="image-20230721082934646" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210829679.png" /></p>
<p>一个训练过程会由多个数据小批次（mini-batch）完成。在图中，一个数据小批次被标示为 <strong>数据</strong> 。训练系统会利用数据小批次生成梯度，提升模型精度。这个过程由一个训练 <strong>程序</strong> 实现。在实际中，这个程序往往实现了一个多层神经网络的执行过程。该神经网络的执行由一个计算图（Computational Graph）表示。这个图有多个相互连接的算子（Operator），每个算子会拥有计算参数。每个算子往往会实现一个神经网络层（Neural Network Layer），而参数则代表了这个层在训练中所更新的的权重（Weights)。</p>
<p>为了更新参数，计算图的执行分为前向计算和反向计算两个阶段。前向计算的第一步会将数据读入第一个算子，该算子会根据当前的参数，计算出计算给下一个算子的数据。算子依次重复这个前向计算的过程（执行顺序：算子1，算子2，算子3），直到最后一个算子结束。最后的算子随之马上开始反向计算。反向计算中，每个算子依次计算出梯度（执行顺序：梯度3，梯度2，梯度1），并利用梯度更新本地的参数。反向计算最终在第一个算子结束。反向计算的结束也标志本次数据小批次的结束，系统随之读取下一个数据小批次，继续更新模型。</p>
<p>给定一个模型训练任务，人们会对 <strong>数据</strong> 和 <strong>程序</strong> 切分（Partition），从而完成并行加速。下表总结了不同的切分方法，单节点训练系统可以被归类于单程序单数据模式。而假如用户希望使用更多的设备实现并行计算，首先可以选择对数据进行分区，并将同一个程序复制到多个设备上并行执行。这种方式是单程序多数据模式，常被称为数据并行（Data Parallelism）。另一种并行方式是对程序进行分区（模型中的算子会被分发给多个设备分别完成）。这种模式是多程序单数据模式，常被称为模型并行（Model Parallelism）。当训练超大型智能模型时，开发人员往往要同时对数据和程序进行切分，从而实现最高程度的并行。这种模式是多程序多数据模式，常被称为混合并行（Hybrid Parallelism）。</p>
<p><img alt="image-20230721083715370" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210837390.png" /></p>
<h3 id="_9">数据并行<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h3>
<p>数据并行往往可以解决单节点算力不足的问题。这种并行方式在人工智能框架中最为常见，具体实现包括：TensorFlow DistributedStrategy、PyTorch Distributed、Horovod DistributedOptimizer等。在一个数据并行系统中，假设用户给定一个训练批大小为<span class="arithmatex">\(N\)</span>，并且希望使用<span class="arithmatex">\(M\)</span>个并行设备来加速训练。那么，该训练批大小会被分为<span class="arithmatex">\(M\)</span>个分区，每个设备会分配到<span class="arithmatex">\(N/M\)</span>个训练样本。这些设备共享一个训练程序的副本，在不同数据分区上独立执行、计算梯度。不同的设备（假设设备编号为<span class="arithmatex">\(i\)</span>）会根据本地的训练样本计算出梯度<span class="arithmatex">\(G_i\)</span>。为了确保训练程序参数的一致性，本地梯度<span class="arithmatex">\(G_i\)</span>需要聚合，计算出平均梯度<span class="arithmatex">\((\sum_{i=1}^{N} G_i) / N\)</span>。最终，训练程序利用平均梯度修正模型参数，完成小批次的训练。</p>
<p>下图展示了两个设备构成的数据并行训练系统（Data Parallel Training System）的例子。假设用户给定的数据批大小是64，那么每个设备会分配到32个训练样本，并且具有相同的神经网络参数（程序副本）。本地的训练样本会依次通过这个程序副本中的算子，完成前向计算和反向计算。在反向计算的过程中，程序副本会生成局部梯度。不同设备上对应的局部梯度（如设备1和设备2上各自的梯度1）会进行聚合，从而计算平均梯度。这个聚合的过程往往由集合通信的AllReduce操作完成。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210906624.png" alt="image-20230721090653584" style="zoom:80%;" /></p>
<h3 id="_10">模型并行<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<p>模型并行往往用于解决单节点内存不足的问题。一个常见的内存不足场景是模型中含有大型算子，例如深度神经网络中需要计算大量分类的全连接层。完成这种大型算子计算所需的内存可能超过单设备的内存容量。那么需要对这个大型算子进行切分。假设这个算子具有<span class="arithmatex">\(P\)</span>个参数，而系统拥有<span class="arithmatex">\(N\)</span>个设备，那么可以将<span class="arithmatex">\(P\)</span>个参数平均分配给<span class="arithmatex">\(N\)</span>个设备（每个设备分配<span class="arithmatex">\(P/N\)</span>个参数），从而让每个设备负责更少的计算量，能够在内存容量的限制下完成前向计算和反向计算。这种切分方式是模型并行训练系统（Model Parallelism Training System）的一种应用，也被称为<strong>算子内并行</strong>（Intra-operator Parallelism）。</p>
<p><img alt="image-20230721090916904" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210909941.png" /></p>
<p>给出了一个由两个设备实现的算子内并行的例子。在这个例子中，假设一个神经网络具有两个算子，算子1的计算（包含正向和反向计算）需要预留16GB的内存，算子2的计算需要预留1GB的内存。而本例中的设备最多可以提供10GB的内存。为了完成这个神经网络的训练，需要对算子1实现并行。具体做法是，将算子1的参数平均分区，设备1和设备2各负责其中部分算子1的参数。由于设备1和设备2的参数不同，因此它们各自负责程序分区1和程序分区2。在训练这个神经网络的过程中，训练数据（按照一个小批次的数量）会首先传给算子1。由于算子1的参数分别由两个设备负责，因此数据会被广播（Broadcast）给这两个设备。不同设备根据本地的参数分区完成前向计算，生成的本地计算结果需要进一步合并，发送给下游的算子2。在反向计算中，算子2的数据会被广播给设备1和设备2，这些设备根据本地的算子1分区各自完成局部的反向计算。计算结果进一步合并计算回数据，最终完成反向计算。</p>
<p>另一种内存不足的场景是：模型的总内存需求超过了单设备的内存容量。在这种场景下，假设总共有<span class="arithmatex">\(N\)</span>个算子和<span class="arithmatex">\(M\)</span>个设备，可以将算子平摊给这<span class="arithmatex">\(M\)</span>个设备，让每个设备仅需负责<span class="arithmatex">\(N/M\)</span>个算子的前向和反向计算，降低设备的内存开销。这种并行方式是模型并行的另一种应用，被称为<strong>算子间并行</strong>（Inter-operator Parallelism）。</p>
<p><img alt="image-20230721090932241" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210909277.png" /></p>
<p>给出了一个由两个设备实现的算子间并行的例子。在这个例子中，假设一个神经网络具有两个算子，算子1和算子2各自需要10GB的内存完成计算，则模型总共需要20GB的内存。而每个设备仅能提供10GB内存。在这个例子中，用户可以把算子1放置在设备1上，算子2放置在设备2上。在前向计算中，算子1的输出会被发送（Send）给下游的设备2。设备2接收（Receive）来自上游的数据，完成算子2的前向计算。在反向计算中，设备2将算子2的反向计算结果发送给设备1。设备1完成算子1的反向计算，完成本次小批次（Mini-Batch）的训练。</p>
<h3 id="_11">混合并行<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h3>
<p><img alt="image-20230721091001242" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210910278.png" /></p>
<p>在训练大型人工智能模型中，往往会同时面对算力不足和内存不足的问题。因此，需要混合使用数据并行和模型并行，这种方法被称为混合并行。上图是一个由4个设备实现的混合并行的例子。在这个例子中，首先实现算子间并行解决训练程序内存开销过大的问题：该训练程序的算子1和算子2被分摊到了设备1和设备2上。进一步，通过数据并行添加设备3和设备4，提升系统算力。为了达到这一点，对训练数据进行分区（数据分区1和数据分区2），并将模型（算子1和算子2）分别复制到设备3和设备4。在前向计算的过程中，设备1和设备3上的算子1副本同时开始，计算结果分别发送（Send）给设备2和设备4完成算子2副本的计算。在反向计算中，设备2和设备4同时开始计算梯度，本地梯度通过AllReduce操作进行平均。反向计算传递到设备1和设备3上的算子1副本结束。</p>
<h2 id="_12">流水线并行<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<p>除了数据并行和模型并行以外，流水线并行是另一种常用的实现分布式训练的方法。流水线并行往往被应用在大型模型并行系统中。这种系统通过算子内并行和算子间并行解决单设备内存不足的问题。然而，这类系统的运行中，计算图中的下游设备（Downstream Device）需要长期持续处于空闲状态，等待上游设备（Upstream Device）的计算完成，才可以开始计算，这极大降低了设备的平均使用率。这种现象称为模型并行气泡（Model Parallelism Bubble）。</p>
<p>为了减少气泡，通常可以在训练系统中构建流水线。这种做法是<strong>将训练数据中的每一个小批次划分为多个微批次（Micro-Batch）</strong>。假设一个小批次有<span class="arithmatex">\(D\)</span>个训练样本，将其划分为<span class="arithmatex">\(M\)</span>个微批次，那么一个微批次就有<span class="arithmatex">\(D/M\)</span>个数据样本。每个微批次依次进入训练系统，完成前向计算和反向计算，计算出梯度。每个微批次对应的梯度将会缓存，等到全部微批次完成，缓存的梯度会被加和，算出平均梯度（等同于整个小批次的梯度），完成模型参数的更新。</p>
<p><img alt="image-20230721091036367" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210910396.png" /></p>
<p>上图给出了一个流水线训练系统的执行例子。在本例中，模型参数需要切分给4个设备存储。为了充分利用这4个设备，将小批次切分为两个微批次。假设<span class="arithmatex">\(F_{i,j}\)</span>表示第<span class="arithmatex">\(j\)</span>个微批次的第<span class="arithmatex">\(i\)</span>个前向计算任务，<span class="arithmatex">\(B_{i,j}\)</span>表示第<span class="arithmatex">\(j\)</span>个微批次的第<span class="arithmatex">\(i\)</span>个反向计算任务。当设备1完成第一个微批次的前向计算后（表示为<span class="arithmatex">\(F_{0,0}\)</span>），会将中间结果发送给设备2，触发相应的前向计算任务（表示为<span class="arithmatex">\(F_{1,0}\)</span>）。与此同时，设备1也可以开始第二个微批次的前向计算任务（表示为<span class="arithmatex">\(F_{0,1}\)</span>）。前向计算会在流水线的最后一个设备，即设备3，完成。</p>
<p>系统于是开始反向计算。设备4开始第1个微批次的反向计算任务（表示为<span class="arithmatex">\(B_{3,0}\)</span>）。该任务完成后的中间结果会被发送给设备3，触发相应的反向计算任务（表示为<span class="arithmatex">\(B_{2,0}\)</span>）。与此同时，设备4会缓存对应第1个微批次的梯度，接下来开始第2个微批次计算（表示为<span class="arithmatex">\(B_{3,1}\)</span>）。当设备4完成了全部的反向计算后，会将本地缓存的梯度进行相加，并且除以微批次数量，计算出平均梯度，该梯度用于更新模型参数。</p>
<p>需要注意的是，计算梯度往往需要前向计算中产生的激活值。经典模型并行系统中会将激活值缓存在内存中，反向计算时就可以直接使用，避免重复计算。而在流水线训练系统中，由于内存资源紧张，前向计算中的激活值往往不会缓存，而是在反向计算中重新计算（Recomputation）。</p>
<p>在使用流水线训练系统中，时常需要调试微批次的大小，从而达到最优的系统性能。当设备完成前向计算后，必须等到全部反向计算开始，在此期间设备会处于空闲状态。可以看到设备1在完成两个前向计算任务后，要等很长时间才能开始两个反向计算任务。这其中的等待时间即被称为流水线气泡（Pipeline Bubble）。为了减少设备的等待时间，一种常见的做法是尽可能地增加微批次的数量，从而让反向计算尽可能早开始。然而，使用非常小的微批次，可能会造成微批次中的训练样本不足，从而无法充分的利用起来硬件加速器中的海量计算核心。因此最优的微批次数量由多种因素（如流水线深度、微批次大小和加速器计算核心数量等）共同决定。</p>
<h2 id="_13">机器学习集群架构<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<p>机器学习模型的分布式训练通常会在计算集群（Compute Cluster）中实现。接下来，我们将介绍计算集群的构成，特别是其集群网络的设计。</p>
<p><img alt="image-20230721094043286" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210940325.png" /></p>
<p>上图描述了一个机器学习集群的典型架构。这种集群中会部署大量带有硬件加速器的服务器。每个服务器中往往有多个加速器。为了方便管理服务器，多个服务器会被放置在一个机柜（Rack）中，同时这个机柜会接入一个架顶交换机（Top of Rack Switch）。在架顶交换机满载的情况下，可以通过在架顶交换机间增加骨干交换机（Spine Switch）进一步接入新的机柜。这种连接服务器的拓扑结构往往是一个多层树（Multi-Level Tree）。</p>
<p>需要注意的是，在集群中跨机柜通信（Cross-Rack Communication）往往会有网络瓶颈。这是因为集群网络为了便于硬件采购和设备管理，会采用统一规格的网络链路。因此，在架顶交换机到骨干交换机的网络链路常常会形成网络带宽超额认购（Network Bandwidth Oversubscription），即峰值带宽需求会超过实际网络带宽。如上图的集群内，当服务器1和服务器2利用各自的网络链路（假设10Gb/s）往服务器3发送数据时，架顶交换机1会汇聚2倍数据（即20Gb/s）需要发往骨干交换机1。然而骨干交换机1和架顶交换机1 之间只有一条网络链路（10Gb/s）。这里，峰值的带宽需求是实际带宽的两倍，因此产生网络超额订购。<strong>在实际的机器学习集群中，实际带宽和峰值带宽的比值一般在1:4到1:16之间</strong>。因此如果将网络通信限制在机柜内，从而避免网络瓶颈成为了分布式机器学习系统的核心设计需求。</p>
<p>那么，在计算集群中训练大型神经网络需要消耗多少网络带宽呢？假设给定一个千亿级别参数的神经网络（比如OpenAI 发布的大型语言模型GPT-3有最多将近1750亿参数），如果用32位浮点数来表达每一个参数，那么每一轮训练迭代（Training Iteration）训练中，一个数据并行模式下的模型副本（Model Replica）则需要生成700GB，即175G <span class="arithmatex">\(*\)</span> 4 bytes = 700GB，的本地梯度数据。假如有3个模型副本，那么至少需要传输1.4TB，即700GB <span class="arithmatex">\(*\)</span> <span class="arithmatex">\((3-1)\)</span>，的梯度数据。这是因为对于<span class="arithmatex">\(N\)</span>个副本，只需传送其中的<span class="arithmatex">\(N-1\)</span>个副本完成计算。当平均梯度计算完成后，需要进一步将其广播（Broadcast）到全部的模型副本（即1.4TB的数据）并更新其中的本地参数，从而确保模型副本不会偏离（Diverge）主模型中的参数。</p>
<p><strong>当前的机器学习集群一般使用以太网（Ethernet）构建不同机柜之间的网络</strong>。主流的商用以太网链路带宽一般在10Gb/s到25Gb/s之间。这里需要注意的是，网络带宽常用Gb/s为单位，而内存带宽常用GB/s为单位。前者以比特（bit）衡量，后者以字节（byte）衡量。</p>
<p>利用以太网传输海量梯度会产生严重的传输延迟。<strong>新型机器学习集群（如英伟达的DGX系列机器）往往配置有更快的InfiniBand。</strong>单个InfiniBand链路可以提供100Gb/s或200Gb/s的带宽。即使拥有这种高速网络，传输TB级别的本地梯度依然需要大量延迟（即使忽略网络延迟，1TB的数据在200Gb/s的链路上传输也需要至少40s）。<strong>InfiniBand的编程接口以远端内存直接读取（Remote Direct Memory Access，RDMA）为核心，提供了高带宽，低延迟的数据读取和写入函数</strong>。然而，RDMA的编程接口和传统以太网的TCP/IP的Socket接口有很大不同，为了解决兼容性问题，人们可以用IPoIB (IP-over-InfiniBand)技术。这种技术确保了遗留应用（Legacy Application）可以保持Socket调用，而底层通过IPoIB调用InfiniBand的RDMA接口。</p>
<p>为了在服务器内部支持多个加速器（通常2-16个），通行的做法是在服务器内部构建一个异构网络。以上图中的服务器1为例，这个服务器放置了两个CPU，CPU之间通过QuickPath Interconnect (QPI)进行通信。而在一个CPU接口（Socket）内，加速器和CPU通过PCIe总线（Bus）互相连接。由于加速器往往采用高带宽内存（High-Bandwidth Memory，HBM）。HBM的带宽（例如英伟达A100的HBM提供了1935 GB/s的带宽）远远超过PCIe的带宽（例如英伟达A100服务器的PCIe 4.0只能提供64GB/s的带宽）。在服务器中，PCIe需要被全部的加速器共享。当多个加速器同时通过PCIe进行数据传输时，PCIe就会成为显著的通信瓶颈。为了解决这个问题，机器学习服务器往往会引入加速器高速互连（Accelerator High-speed Interconnect），例如英伟达A100 GPU的NVLink提供了600 GB/s的带宽，从而绕开PCIe进行高速通信。</p>
<h2 id="_14">集合通信<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<h3 id="_15">常见集合通信算子<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h3>
<h4 id="_16">通信模型<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h4>
<p>假定在一个分布式机器学习集群中，存在<span class="arithmatex">\(p\)</span>个计算设备，并由一个网络来连接所有的设备。每个设备有自己的独立内存，并且所有设备间的通信都通过该网络传输。同时，每个设备都有一个编号<span class="arithmatex">\(i\)</span>，其中<span class="arithmatex">\(i\)</span>的范围从<span class="arithmatex">\(1\)</span>到<span class="arithmatex">\(p\)</span>。
设备之间的点对点（Point-to-Point, P2P）通信由全双工传输（Full-Duplex Transmission)实现。该通信模型的基本行为可以定义如下：</p>
<ul>
<li>每次通信有且仅有一个发送者（Sender）和一个接收者（Receiver）。在某个特定时刻，每个设备仅能至多发送或接收一个消息（Message）。每个设备可以同时发送一个消息和接收一个消息。一个网络中可以同时传输多个来自于不同设备的消息。</li>
<li>传输一个长度为<span class="arithmatex">\(l\)</span>个字节（Byte）的消息会花费<span class="arithmatex">\(a+b \times l\)</span>的时间，其中<span class="arithmatex">\(a\)</span>代表延迟（Latency），即一个字节通过网络从一个设备出发到达另一个设备所需的时间；<span class="arithmatex">\(b\)</span>代表传输延迟（Transmission Delay），即传输一个具有<span class="arithmatex">\(l\)</span>个字节的消息所需的全部时间。前者取决于两个设备间的物理距离（如跨设备、跨机器、跨集群等），后者取决于通信网络的带宽。需要注意的是，这里简化了传输延迟的定义，其并不考虑在真实网络传输中会出现的丢失的消息（Dropped Message）和损坏的消息（Corrupted Message）的情况。</li>
</ul>
<h4 id="broadcast">Broadcast<a class="headerlink" href="#broadcast" title="Permanent link">&para;</a></h4>
<p><img alt="image-20230721095104074" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210951109.png" /></p>
<p>一个分布式机器学习系统经常需要将一个设备<span class="arithmatex">\(i\)</span>上的模型参数或者配置文件广播（Broadcast）给其余全部设备。因此，可以把Broadcast算子定义为从编号为<span class="arithmatex">\(i\)</span>的设备发送长度为<span class="arithmatex">\(l\)</span>字节的消息给剩余的<span class="arithmatex">\(p-1\)</span>个设备。</p>
<p>一种简单实现Broadcast的算法是在设备<span class="arithmatex">\(i\)</span>上实现一个循环，该循环使用<span class="arithmatex">\(p-1\)</span>次Send/Receive操作来将数据传输给相应设备。然而，该算法不能达到并行通信的目的（该算法只有<span class="arithmatex">\((a+b \times l) \times (p-1)\)</span>的线性时间复杂度）。为此，可以利用分治思想对上述简单实现的Broadcast算法进行优化。假设所有的设备可以重新对编号进行排列，使得Broadcast的发送者为编号为<span class="arithmatex">\(1\)</span>的设备。同时，为了简化计算过程，假设对某个自然数<span class="arithmatex">\(n\)</span>，<span class="arithmatex">\(p = 2^n\)</span>。 现在，可以通过从1 向 <span class="arithmatex">\(p/2\)</span> 发送一次信息把问题转换为两个大小为<span class="arithmatex">\(p/2\)</span>的子问题：编号为1的设备对编号1到编号<span class="arithmatex">\(p/2-1\)</span> 的Broadcast，以及编号为<span class="arithmatex">\(p/2\)</span>的设备对编号<span class="arithmatex">\(p/2\)</span>到编号<span class="arithmatex">\(p\)</span>的Broadcast。我们便可以通过在这两个子问题上进行递归来完成这个算法，并把临界条件定义为编号为<span class="arithmatex">\(i\)</span>的设备在<span class="arithmatex">\([i,i]\)</span>这个区间中的Broadcast。此时，由于<span class="arithmatex">\(i\)</span>本身已经拥有该信息，不需要做任何操作便可直接完成Broadcast。这个优化后的算法为<span class="arithmatex">\((a+b \times l) \times \log p\)</span> 时间复杂度，因为在算法的每一阶段（编号为<span class="arithmatex">\(t\)</span>），有<span class="arithmatex">\(2^t\)</span>个设备在并行运行Broadcast算子。同时，算法一定会在<span class="arithmatex">\(\log p\)</span> 步之内结束。</p>
<h4 id="reduce">Reduce<a class="headerlink" href="#reduce" title="Permanent link">&para;</a></h4>
<p>在分布式机器学习系统中，另一个常见的操作是将不同设备上的计算结果进行聚合（Aggregation）。例如，将每个设备计算的本地梯度进行聚合，计算梯度之和（Summation）。这些聚合函数（表达为<span class="arithmatex">\(f\)</span>）往往符合结合律（Associative Law）和交换律（Commutative Law）。这些函数由全部设备共同发起，最终聚合结果存在编号为<span class="arithmatex">\(i\)</span>的设备上。常见聚合函数有加和、乘积、最大值和最小值。集合通信将这些函数表达为Reduce算子。</p>
<p>一个简易的Reduce的优化实现同样可以用分治思想来实现，即把<span class="arithmatex">\(1\)</span>到<span class="arithmatex">\(p/2-1\)</span>的Reduce结果存到编号为<span class="arithmatex">\(1\)</span>的设备中，然后把<span class="arithmatex">\(p/2\)</span>到<span class="arithmatex">\(p\)</span>的Reduce结果存到<span class="arithmatex">\(p/2\)</span>上。最后，可以把<span class="arithmatex">\(p/2\)</span>的结果发送至<span class="arithmatex">\(1\)</span>，执行<span class="arithmatex">\(f\)</span>，并把最后的结果存至<span class="arithmatex">\(i\)</span>。假设<span class="arithmatex">\(f\)</span>的运行时间复杂度为常数并且其输出信息的长度<span class="arithmatex">\(l\)</span>不改变，Reduce的时间复杂度仍然为<span class="arithmatex">\((a+b \times l) \times \log p\)</span>。</p>
<h4 id="allreduce">AllReduce<a class="headerlink" href="#allreduce" title="Permanent link">&para;</a></h4>
<p>集合通信通过引入AllReduce算子，从而将Reduce函数<span class="arithmatex">\(f\)</span>的结果存至所有设备上。</p>
<p>一种简单的AllReduce实现方法是首先调用Reduce算法并将聚合结果存到编号为<span class="arithmatex">\(1\)</span>的设备上。然后，再调用Broadcast算子将聚合结果广播到所有的设备。这种简单的AllReduce实现的时间复杂度为<span class="arithmatex">\((a+b \times l) \times \log p\)</span>。</p>
<h4 id="gather">Gather<a class="headerlink" href="#gather" title="Permanent link">&para;</a></h4>
<p>Gather算子可以将全部设备的数据全部收集（Gather）到编号为<span class="arithmatex">\(i\)</span>的设备上。</p>
<p>在收集函数（Gather Function）符合结合律和交换律的情况下，可以通过将其设为Reduce算子中的<span class="arithmatex">\(f\)</span>来实现Gather算子。但是，在这种情况下，无论是基于链表还是数组的实现，在每一步的Reduce操作中<span class="arithmatex">\(f\)</span>的时间复杂度和输出长度<span class="arithmatex">\(l\)</span>都发生了改变。因此，Gather的时间复杂度是<span class="arithmatex">\(a \times \log p + (p-1) \times b \times l\)</span>。这是因为在算法的每一阶段<span class="arithmatex">\(t\)</span>，传输的信息长度为<span class="arithmatex">\(2^{t} \times l\)</span>。</p>
<h4 id="allgather">AllGather<a class="headerlink" href="#allgather" title="Permanent link">&para;</a></h4>
<p>AllGather算子会把收集的结果分发到全部的设备上。</p>
<p>在这里，一个简单的方法是使用Gather和Broadcast算子把聚合结果先存到编号为1的设备中，再将其广播到剩余的设备上。这会产生一个<span class="arithmatex">\(a \times \log p + (p-1) \times b \times l + (a+p \times l \times b) \times \log p\)</span>的时间复杂度，因为在广播时，如果忽略链表/数组实现所带来的额外空间开销，每次通信的长度为<span class="arithmatex">\(pl\)</span>而不是<span class="arithmatex">\(l\)</span>。简化后，得到了一个<span class="arithmatex">\(a \times  \log p + p \times l \times b \times \log p\)</span> 的时间复杂度。在一个基于<a href="https://link.springer.com/book/10.1007/978-3-030-25209-0">超立方体</a>的算法下，可以将其进一步优化到和Gather算子一样的时间复杂度<span class="arithmatex">\(a \times \log p + (p-1) \times b \times l\)</span>，由于篇幅问题此处便不再赘述。</p>
<h4 id="scatter">Scatter<a class="headerlink" href="#scatter" title="Permanent link">&para;</a></h4>
<p>Scatter算子可以被视作Gather算子的逆运算：把一个存在于编号为<span class="arithmatex">\(i\)</span>的设备上，长度为<span class="arithmatex">\(p\)</span>（信息长度为<span class="arithmatex">\(p \times  l\)</span>）的链式数据结构<span class="arithmatex">\(L\)</span>中的值分散到每个设备上，使得编号为<span class="arithmatex">\(i\)</span>的设备会得到<span class="arithmatex">\(L[i]\)</span>的结果。</p>
<p>可以通过模仿Gather算法设计一个简易的Scatter实现：每一步的运算中，我们把现在的子链继续对半切分，并把前半段和后半段作为子问题进行递归。这时候，在算法的每一阶段<span class="arithmatex">\(t\)</span>，传输的信息长度为<span class="arithmatex">\(l \times  2^{(m-t)}\)</span>，其中<span class="arithmatex">\(m\)</span>是算法总共运行的步骤，不会超过<span class="arithmatex">\(\log p\)</span> （见Broadcast算子的介绍）。最终，Scatter算子的简易实现和Gather算子一样都有<span class="arithmatex">\(a \times \log p + (p-1)  \times b \times l\)</span> 的时间复杂度。在机器学习系统中，Scatter算子经常同时被用于链式数据结构和可切分的数据结构，例如张量在一个维度上的<span class="arithmatex">\(p\)</span>等分等。</p>
<h3 id="allreduce_1">基于AllReduce的梯度平均算法<a class="headerlink" href="#allreduce_1" title="Permanent link">&para;</a></h3>
<p>下面讨论如何利用AllReduce算子实现大型集群中的高效梯度平均。首先，参照前面的分析，可以考虑一种简单的计算平均梯度的方法：在集群中分配一个设备收集本地梯度，并在计算平均梯度后再将其广播到全部的设备。这种做法易于实现，但是引入了两个问题。首先，多台设备同时给该聚合设备发送数据时，聚合设备会因严重的带宽不足产生网络拥塞。其次，单台设备需要负担大量的梯度平均计算，而受限于单台设备上的有限算力，这种计算往往会受限于算力瓶颈。</p>
<p>为了解决上述问题，可以引入AllReduce算子的Reduce-Broadcast实现来优化算法，其设计思路是：通过让全部的节点参与到梯度的网络通信和平均计算中，将巨大的网络和算力开销均摊给全部节点。这种做法可以解决先前单个梯度聚合节点的问题。假设有<span class="arithmatex">\(M\)</span>个设备，每个设备存有一个模型副本，该模型由<span class="arithmatex">\(N\)</span>个参数/梯度构成。那么按照AllReduce算子的要求，需要先将全部的参数按照设备数量切分成<span class="arithmatex">\(M\)</span>个分区（Partition），使得每个分区具有<span class="arithmatex">\(N/M\)</span>个参数。首先给出这个算法的初始和结束状态。AllReduce的例子所示，该例子含有3个设备。在每个设备有一个模型副本的情况下，这个副本有3个参数。那么按照AllReduce的分区方法，参数会被划分成3个分区（3个设备），而每一个分区则有1个参数（<span class="arithmatex">\(N/M\)</span>，<span class="arithmatex">\(N\)</span>代表3个参数，<span class="arithmatex">\(M\)</span>代表3个设备）。在这个例子中，假定设备1拥有参数2,4,6，设备2拥有参数1,2,3，设备3拥有参数4,8,12，那么在使用一个AllReduce算子进行计算过后，全部的设备都将拥有梯度相加后的结果7,14,21，其中分区1的结果7是由3个设备中分区1的初始结果相加而成（7 = 1 + 2 + 4）。为了计算平均梯度，每个设备只需要在最后将梯度之和除以设备数量即可（分区1的最终结果为7除以3）。</p>
<p><img alt="image-20230721100613036" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307211006077.png" /></p>
<p>AllReduce算子会把梯度的计算拆分成<span class="arithmatex">\(M-1\)</span>个Reduce算子和<span class="arithmatex">\(M-1\)</span>个Broadcast算子（其中<span class="arithmatex">\(M\)</span>是节点的数量）。其中，Reduce算子用于计算出梯度的加和，Broadcast算子用于把梯度之和广播给全部的节点。上图展示了一个AllReduce算子的执行过程。AllReduce算子由Reduce算子开始，在第一个Reduce算子中，AllReduce算子会对全部节点进行配对（Pairing），让它们共同完成梯度相加的操作。在第一个Reduce算子中，设备1和设备2进行了配对共同对分区1的数据相加。其中，设备2把本地的梯度数据1发送给设备1，设备1将接收到的梯度数据1和本地的分区1内的梯度数据2进行相加，计算出中间梯度相加的结果3。与此同时，设备1和设备3进行配对，共同完成对分区3的数据相加。而设备3和设备2进行配对，共同完成对于分区2的数据相加。</p>
<p>上述的Reduce算子对梯度的分布式计算实现了以下的性能优化:</p>
<ul>
<li><strong>网络优化：</strong> 全部设备都同时在接收和发送数据，利用起了每个设备的入口（Ingress）和出口（Egress）带宽。因此在AllReduce算法的过程中，可利用的带宽是<span class="arithmatex">\(M * B\)</span>，其中<span class="arithmatex">\(M\)</span>是节点数量，<span class="arithmatex">\(B\)</span>是节点带宽，从而让系统实现网络带宽上的可扩展性。</li>
<li><strong>算力优化：</strong> 全部设备的处理器都参与了梯度相加的计算。因此在AllReduce算法的过程中，可利用的处理器是<span class="arithmatex">\(M * P\)</span>，其中<span class="arithmatex">\(M\)</span>是节点数量，<span class="arithmatex">\(P\)</span>是单个设备的处理器数量，从而让系统实现计算上的可扩展性。</li>
<li><strong>负载均衡：</strong> 由于数据分区是平均划分的，因此每次设备分摊到的通信和计算开销是相等的。</li>
</ul>
<p>在接下来的Reduce算子中，AllReduce算法会对不同数据分区选择另外的配对方法。例如，在第二个Reduce算子中，AllReduce算法会将设备1和设备3进行配对，负责分区1的数据相加。将设备1和设备2进行配对，负责分区2。将设备2和设备3进行配对，负责分区3。在一个3个节点的AllReduce集群里，在2个Reduce算子完成后，就计算出了每个分区的数据相加结果（分区1的数据相加结果7此时在设备3上，分区2的数据相加结果14此时在设备1上，分区3的数据相加结果21此时在设备2上）。</p>
<p>接下来，AllReduce算法将进入Broadcast阶段。这一阶段的过程和Reduce算子类似，核心区别是节点进行配对后，它们不再进行数据相加，而是将Reduce的计算结果进行广播。在第一个Broadcast算子中，设备1会将分区2的结果14直接写入设备3的分区2中。设备2会将分区3的结果21直接写入设备1中。设备3会将分区1的结果直接写入设备2中。在一个3个节点的AllReduce集群中，我们会重复2次Broadcast算子将每个分区的Reduce结果告知全部的节点。</p>
<p>在本节中，我们讨论了AllReduce的其中一种常用实现方法。根据集群网络拓扑的不同，人们也会用以下的方法来实现AllReduce：<a href="https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4">树形结构</a>，<a href="https://github.com/baidu-research/baidu-allreduce">环形结构</a>，<a href="https://arxiv.org/abs/1811.05233}">二维环面结构</a>以及<a href="https://github.com/NVIDIA/nccl/issues/320">CollNet</a>。在此我们不展开讨论。</p>
<h3 id="_17">集合通信算法性能分析<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h3>
<p>在讨论集合通信算子的性能时，人们经常会使用一些数值化指标量化不同的算法实现。在计算点对点通信所需的时间时，会在信息长度上乘以一个系数<span class="arithmatex">\(b\)</span>。这个数值化指标就是算法带宽（Algorithm Bandwidth），泛指单位时间内执行操作（通信和计算等）的数量。一般计算公式为<span class="arithmatex">\(b = s/t\)</span>，其中<span class="arithmatex">\(s\)</span>代指操作的大小，<span class="arithmatex">\(t\)</span>指操作指定的两个端点之间所经过的时间。以P2P通信举例，可以通过衡量一个大小已知的信息<span class="arithmatex">\(m\)</span>在执行Send函数时所花的时间来确定两个设备之间网络的带宽。</p>
<p>前文提到，在计算点对点通信所需的时间是，会在信息长度之上乘以一个系数b。这个系数就是算法带宽，泛指单位时间内执行操作（通信，计算等）的数量。一般计算公式为<span class="arithmatex">\(b = s/t\)</span>，其中<span class="arithmatex">\(s\)</span>代指操作的大小，<span class="arithmatex">\(t\)</span>指操作指定的两个端点之间所经过的时间。以点到点通信举例，我们可以通过衡量一个大小已知的信息<span class="arithmatex">\(m\)</span>在执行send函数时所花的时间来确定两个处理单元之间网络的带宽。</p>
<p>虽然算法带宽的计算方法既简单又高效，但很难将其拓展至对于集合通信算子的带宽计算。这是因为，取决于具体算子和算法实现的不同，一个集合通信算子在执行过程中测得的算法带宽往往会远小于硬件本身的最高带宽。在实际运行相应的测试中，经常能观测到随着设备增加，算法带宽呈下降趋势。为了解决这一问题，NCCL提出了总线带宽（Bus Bandwidth）这一数值化指标，将根据每个集合通信算子的分析所测得的算法带宽乘以一个校正系数（Correction Factor），从而给出贴近实际硬件表现的带宽值。下面给出常见算子的校正系数：</p>
<ul>
<li>AllReduce：对于在设备<span class="arithmatex">\(n_1, n_2, \cdots, n_p\)</span> 上的值 <span class="arithmatex">\(v_1, v_2, \cdots, v_p\)</span> 计算 <span class="arithmatex">\(v_1 o v_2 o \cdots o v_p\)</span>（其中<span class="arithmatex">\(o\)</span>为符合结合律的算子），再存回每个设备中。在不考虑实际实现算法和网络拓扑的情况下，这个操作在理论上只需要<span class="arithmatex">\(2 \times  (p-1)\)</span>次数据传输，其中包含在每个设备上分开进行的<span class="arithmatex">\(p-1\)</span>次 <span class="arithmatex">\(o\)</span>的运算，以及最后 <span class="arithmatex">\(p\)</span> 次最终数据值的广播，再减去第一个设备的运算和最后一个设备的广播对运行时间的影响。假设每个设备对于外界所有信息处理的带宽为<span class="arithmatex">\(B\)</span>，可以得出对于<span class="arithmatex">\(S\)</span>个在不同设备上的数据运行AllReduce算子能得到最优情况下的运行时间：<span class="arithmatex">\(t = (2 \times S \times  (p-1)) / (p*B)\)</span>，进行简化后可得 <span class="arithmatex">\(B = (S/t) \times  (2 \times  (p-1)/p) = b (2 \times  (p-1)/p)\)</span>。这里的 <span class="arithmatex">\(2(p-1)/p\)</span>便是校正系数。</li>
<li>ReduceScatter：对于每个设备来说，可以把ReduceScatter理解为只执行AllReduce中的聚合部分。对此，只需要考虑上面分析中的<span class="arithmatex">\(n-1\)</span>次<span class="arithmatex">\(op\)</span>的运算，整理后可得<span class="arithmatex">\(B = (S/t) \times  ((p-1)/p) = b \times  ((p-1)/p)\)</span>。即校正系数为<span class="arithmatex">\(b \times  ((p-1)/p)\)</span>。</li>
<li>AllGather：对于每个设备来说，可以把AllGather理解为只执行AllReduce中的广播部分，同理可得<span class="arithmatex">\(B = (S/t) \times  ((p-1)/p) = b \times  ((p-1)/p)\)</span>。即校正系数为<span class="arithmatex">\(b \times  ((p-1)/p)\)</span>。</li>
<li>Broadcast：与AllReduce不同的是，Broadcast中所有数据需要从算子本身的发送者发出。即使在上面分治的情况下，也需要等待所有子问题运行结束才能确保Broadcast算子本身的正确性。因此，在计算带宽时，瓶颈仍为发送者对于外界所有信息处理的带宽，所以 <span class="arithmatex">\(B = S/t\)</span>，即校正系数为<span class="arithmatex">\(1\)</span>。</li>
<li>Reduce：Reduce需要将所有数据送往算子的接收者，因此校正系数为<span class="arithmatex">\(1\)</span>。</li>
</ul>
<p>由于Gather和Scatter的带宽计算与实际聚合/分散时的数据结构相关性更高，故不给出特定的校正系数。</p>
<h3 id="_18">利用集合通信优化模型训练的实践<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h3>
<p>针对不同的集群，机器学习系统往往会灵活组合不同集合通信算子来最大化通信效率。下面提供两个案例分析：ZeRO和DALL-E。</p>
<h4 id="zero">ZeRO<a class="headerlink" href="#zero" title="Permanent link">&para;</a></h4>
<p>ZeRO是微软提出的神经网络优化器，在实践中成功训练了2020年世界上最大的语言模型（高达1700亿参数）。在训练这个级别的神经网络时优化器本身的参数，反向计算时的梯度，以及模型参数本身都会对加速器内存空间产生极大的压力。通过简易的计算不难得出，1700亿参数的模型在32位浮点表示情况下会占用至少680GB的内存，远超于现在内存最高的加速器A100 （最高内存80GB）。于是，需要考虑如何高效地把模型切成数份存储在不同的加速器上，以及如何高效地通过使用集合通信算子来进行模型训练和推理。这里，介绍三个主要的关于集合通信的优化技术：</p>
<ul>
<li><strong>单一节点上的参数存储：</strong> 现代集群中节点内部加速器的带宽远大于节点之间的带宽。为此，需要尽量减少节点间的通信，并且保证大部分通信仅存在于节点内部的加速器之间。在观察模型切片时，又可得模型本身前向和反向计算时需要在不同切片之间进行的通信远小于不同模型副本梯度平均的通信量。针对这一特性，ZeRO选择了将单一模型的全部切片存储到同一节点内部，从而大大提高了训练效率。</li>
<li><strong>基于AllGather算子的前向计算：</strong> 假设模型中的参数在层级上呈线性，便可按照参数在网络上的顺序从前到后将其分别存储到不同加速器中。在前向时，可以注意到某一层的计算仅依赖于其相邻层的参数。对此，可以对所有包含模型参数的加速器进行一次AllGather计算，用来提取每一层的后一层的参数，以及计算该层本身的激活值。为了节约内存，在AllGather操作结束后需要立即丢弃除了该层以外其他层的参数。</li>
<li><strong>基于ReduceScatter算子的梯度平均：</strong> 在反向计算时我们只需要前一层的参数来计算本层的激活值和梯度，因此只需要再次使用AllGather来完成每个加速器上的梯度计算。同时，在聚集梯度后，对于每个加速器仅需要和加速器的编号相同的层数对应的梯度。对此，可以使用ReduceScatter算子直接把相应的梯度存到编号为<span class="arithmatex">\(i\)</span>的加速器上，而不是通常情况下使用AllReduce算子。</li>
</ul>
<h4 id="dall-e">DALL-E<a class="headerlink" href="#dall-e" title="Permanent link">&para;</a></h4>
<p>DALL-E是OpenAI提出的一个基于文字的图片生成模型，模型同样拥有高达120亿的参数。在训练时，除了运用到ZeRO所使用的AllGather + ReduceScatter 技巧，OpenAI团队在其他细节上做了进一步的优化。这里，介绍两个主要的关于集合通信的优化技术：</p>
<ul>
<li><strong>矩阵分解：</strong> 集合通信算子的运行速度和信息本身的长度正相关。在模型训练中，这代表了模型参数本身的大小。对此，DALL-E 选择用矩阵分解（Matrix Factorization）的方法先把高维张量调整为一个二维矩阵，通过分解后分开用集合通信算子进行传输，从而大大减少了通信量。</li>
<li><strong>自定义数据类型：</strong> 一种减少通信量的方法在于修改数据类型本身。显然地，可以使用16位的半精度浮点数，相比正常的32位参数表示可以节省近一倍的通信量。但是，在实践中发现低精度的数据类型会使得模型收敛不稳定，导致最终训练效果大打折扣。为此，OpenAI分析了DALL--E的模型结构，并把其中的参数根据对数据类型精度的敏感性分为了三类。其中对精度最敏感的一类照常使用32位浮点表示并只通过AllReduce算子来同步，而最不敏感的参数则照常通过矩阵分解进行压缩和传输。对于比较敏感的一类，例如Adam优化器其中的动能（Moments）和方差（Variance）参数，OpenAI 基于 IEEE 754 标准实现了两个全新的数据类型：1-6-9和0-6-10（其中第一表示正负所需的位数，第二表示指数所需的位数，第三表示有效数字所需的位数），在节省空间的同时保证了训练的收敛。</li>
</ul>
<h3 id="_19">集合通信在数据并行的实践<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h3>
<p>数据并行作为最广泛使用的分布式训练方法，是集合通信首先需要支持的范式。
对于数据并行的支持，机器学习系统通常提供了两个级别的抽象：在第一种级别的抽象里，机器学习系统更与硬件耦合，可以直接调用集合通信算子的库；在另一种级别的抽象里，机器学习系统更偏向神经网络实现，通过内部调用集合通信算子实现分布式训练和推理的机器学习框架。作为算法工程师，通常会接触到后者的抽象（包括Horovod、KungFu、TensorFlow Distributed等），而作为集群的维护者，往往需要深入了解前者的运行原理和具体的调试方法。以 PyTorch 举例，在torch.distributed 命名空间（Namespace）下实现了一系列方便开发者使用的分布式模型训练和推理函数。在其内部，会根据实际运行的集群调用更底层的集合通信算子库，例如MPI，NCCL（前面已有介绍，适用于GPU分布式训练），Gloo（适用于CPU分布式训练）等。下面具体对比PyTorch Distributed和NCCL在AllReduce应用方面的差异：
以下代码通过PyTorch自带的分布式数据并行（Distributed Data Parallel，DDP）方法完成了一次简易的机器学习模型计算。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># 基于PyTorch DDP高层次封装实现AllReduce算法</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="k">def</span> <span class="nf">ddp_allreduce</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">setup</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">model</span> <span class="o">=</span> <span class="n">ToyModel</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="c1"># 通过调用DDP（分布式数据并行）方法将模型在每个处理器上完成初始化</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">ddp_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">ddp_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">ddp_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="c1"># 在反向计算时，框架内部会执行AllReduce算法</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>
<p>下面代码通过Gloo的Python 接口pygloo和Ray完成了一个二维张量的AllReduce计算。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># 基于pygloo底层接口实现AllReduce算法</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="nd">@ray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">num_cpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="k">def</span> <span class="nf">gloo_allreduce</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    <span class="n">context</span> <span class="o">=</span> <span class="n">pygloo</span><span class="o">.</span><span class="n">rendezvous</span><span class="o">.</span><span class="n">Context</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="o">...</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span class="n">Sendbuf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="n">recvbuf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Sendbuf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="n">Sendptr</span> <span class="o">=</span> <span class="n">Sendbuf</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="n">recvptr</span> <span class="o">=</span> <span class="n">recvbuf</span><span class="o">.</span><span class="n">ctypes</span><span class="o">.</span><span class="n">data</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="c1"># 标明发送者和接收者并直接调用AllReduce算法</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    <span class="n">pygloo</span><span class="o">.</span><span class="n">allreduce</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">Sendptr</span><span class="p">,</span> <span class="n">recvptr</span><span class="p">,</span>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>                    <span class="n">Sendbuf</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">pygloo</span><span class="o">.</span><span class="n">glooDataType_t</span><span class="o">.</span><span class="n">glooFloat32</span><span class="p">,</span>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>                    <span class="n">pygloo</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">pygloo</span><span class="o">.</span><span class="n">allreduceAlgorithm</span><span class="o">.</span><span class="n">RING</span><span class="p">)</span>
</code></pre></div>
<p>可以注意到，PyTorch Distributed并没有显式地调用集合通信算子，而是通过DistributedDataParallel方法将分布式训练和非分布式训练之间的不同隐藏了起来。如果需要在不同集群上运行这段代码，只需要在setup 函数内对应地更改PyTorch使用的底层集合通信库即可。在backward函数被调用时，才会真正地使用AllReduce算法。相比，如果想要直接使用Gloo，不仅需要一步一步地创建通信所需要的数据结构，同时也很难和现有的模型训练框架无缝连接。</p>
<h3 id="_20">集合通信在混合并行的实践<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h3>
<p>随着深度学习的发展，模型和训练数据集的规模呈爆发式增长，单机的算力和存储能力已无法满足需求，因此，分布式训练技术成为行业发展趋势。</p>
<p>本章前几节已总结当前常用的分布式并行训练技术方案，如数据并行、模型并行和流水线并行，在复杂场景下，往往需要不同技术点组合使用，才能达到训练大模型的高性能。华为MindSpore开源框架提供混合并行的能力，来支撑大模型分布式训练，用户可以根据自己的需要进行灵活组合。以下通过简单代码示例来说明如何在MindSpore中组合使用数据并行、模型并行和流水线并行训练技术，其他大模型训练技术的使用方法请参照官网教程。</p>
<p>以下代码利用set_auto_parallel_context接口设置并行模式和可用于训练的卡数，同时利用该接口设置流水线并行中的stage数量。通过扩展nn.Cell, 定义了简单的神经网络模型，其中self.matmul1和self.matmul2的两个矩阵乘操作，调用shard接口来配置切分策略，如matmul1将第一个输入按照行切成4份，实则是在数据维度上切分，是数据并行的样例，而matmul2对第二个输入进行列切，采用了模型并行的方式。为了实现流水线并行，以下代码调用nn.PipelineCell接口来包装net_with_loss，并指定流水线并行所需的微批次大小。最后，通过model.train接口来对神经网络进行混合并行训练。</p>
<p>MindSpore提供了shard接口来允许用户配置切分策略。在这种切分的场景下，需要在必要的时候插入集合通信算子来保证计算逻辑的正确性：第一种是切分了单一算子的情况，将算子切分到多卡进行计算，为了保证计算结果和单卡计算结果一致，需要集合通信算子来将多卡计算的部分结果同步聚合到每张卡上；第二种是多算子情况下，相邻算子的切分方式不同，前继算子的计算结果排布在不同的卡上，后续算子的计算需要用到非当前卡上的数据才能进行，此时需要一个集合通信算子来重新排布前继算子的计算结果。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># 基于MindSpore对模型进行混合并行分布式训练</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># 设置并行模式为半自动并行，同时设置训练的卡数</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="s2">&quot;semi_auto_parallel&quot;</span><span class="p">,</span> <span class="n">device_num</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="c1"># 设置流水线并行的stage数量</span>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">pipeline_stages</span><span class="o">=</span><span class="n">stages</span><span class="p">)</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="k">class</span> <span class="nc">DenseMatMulNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">DenseMutMulNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>        <span class="c1"># 通过shard定义算子切分的方式：matmul1是数据并行的样例，matmul2是模型并行的样例</span>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>        <span class="k">return</span> <span class="n">z</span>
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="c1"># 定义训练数据集</span>
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a><span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DATA_PATH&#39;</span><span class="p">)</span>
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a><span class="n">net</span> <span class="o">=</span> <span class="n">DenseMatMulNet</span><span class="p">()</span>
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a><span class="n">loss</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropyExpand</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a><span class="c1"># 用PipelineCell接口包装神经网络，第二个参数指定MicroBatch Size</span>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a><span class="n">net_pipeline</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PipelineCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">micro_size</span><span class="p">)</span>
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net_pipeline</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">)</span>
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a><span class="c1"># 对模型进行迭代训练</span>
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>展示了上述代码中matmul1和matmul2在调用shard函数后的数据排布情况。matmul1算子将输入<span class="arithmatex">\(X\)</span>按照行切成4份后，分别放置在4个计算设备上（D1-D4），<span class="arithmatex">\(W\)</span>不切分，则以复制的形式放置在4个计算设备上，此时matmul1算子计算的结果<span class="arithmatex">\(Y\)</span>，以行切的形式被放置在不同设备上，而matmul2算子在做计算时，需要<span class="arithmatex">\(Y\)</span>的全量数据，因此两个计算算子之间需要插入AllGather集合通信算子，来从4个不同的设备上收集到<span class="arithmatex">\(Y\)</span>的全量数据。MindSpore能够自动识别不同切分方式的算子之间应该插入哪种集合通信算子，并且将该逻辑对用户隐藏，只暴露出shard接口供用户配置，开发者可以通过合理的策略配置，来减少算子间重排布通信算子在神经网络计算图中的占比，以提升混合并行分布式训练的端到端速率。</p>
<p><img alt="image-20230721100708469" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307211007503.png" /></p>
<h2 id="_21">参数服务器<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h2>
<p>接下来介绍另一种常见的分布式训练系统：参数服务器。不同的机器学习框架以不同方式提供参数服务器的实现。TensorFlow 和 MindSpore 内置了参数服务器的实现。PyTorch 需要用户使用 RPC 接口自行实现。同时，我们也有参数服务器的第三方实现，如PS-Lite。</p>
<h3 id="_22">系统架构<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h3>
<p>不同于基于集合通信实现的机器学习系统，参数服务器系统中的服务器会被分配两种角色：训练服务器和参数服务器，其中<strong>参数服务器需要提供充足内存资源和通信资源，训练服务器需要提供大量的计算资源（如硬件加速器）。</strong> 下图描述了带有参数服务器的机器学习集群。这个集群中含有两个训练服务器和两个参数服务器。 假设我们有一个模型，可以切分为两个参数分区。每个分区被分配给一个参数服务器负责参数同步。 在训练的过程中，每个训练服务器都会有完整的模型，根据本地的训练数据集切片（Dataset Shard）训练出梯度。这个梯度会被推送（Push）到各自参数服务器。参数服务器等到两个训练服务器都完成梯度推送，开始计算平均梯度，更新参数。它们然后通知训练服务器来拉取（Pull）最新的参数，开始下一轮训练迭代。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210852335.png" alt="image-20230721085207294" style="zoom:67%;" /></p>
<h3 id="_23">异步训练<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h3>
<p>参数服务器的一个核心作用是可以处理分布式训练服务器中出现的落后者（Straggler）。在之前的讨论中，在每一轮训练结束后，训练服务器都需要计算平均梯度对每一个模型副本进行更新，从而保证下一轮训练开始前，全部模型副本参数的一致性，这种对于参数一致性的确保一般被称为同步训练（Synchronous Training）。同步训练一般有助于训练系统达到更好的模型精度，但是当系统规模变大，往往会观察到落后者服务器的出现。落后者出现的原因很多。常见的原因包括：落后者设备可能和其他设备不在同一个机柜中，因此落后者的通信带宽显著小于其他设备。另外，落后者设备也可能和其他进程共享本地的服务器计算和通信资源，形成资源竞争，从而降低了性能。</p>
<p>落后者对于基于AllReduce的同步训练系统的性能有显著影响，这是因为AllReduce让全部节点参与到平均梯度的计算和通信中，而每个节点负责等量的数据。因此一个落后者的出现，都会让整个AllReduce操作延迟完成。为了解决这个问题，人们常使用参数服务器同步梯度。一种常见的设计是：训练服务器训练出梯度后，会把本地梯度全部推送到参数服务器。参数服务器在等到一定训练服务器（例如90%的训练服务器）的梯度后，就开始计算平均梯度。这样可以确保平均梯度的计算不会被落后者的出现延误。计算好的平均梯度马上推送给全部训练服务器，开始下一轮训练。</p>
<p>解决落后者的另一种常见做法是利用参数服务器实现异步训练(Asynchronous Training)。在一个异步训练系统中，每个训练服务器在训练开始时，有相同的模型参数副本。在训练中，它们计算出梯度后会马上将梯度推送到参数服务器，参数服务器将推送的梯度立刻用于更新参数，并通知训练服务器立刻来拉取最新的参数。在这个过程中，不同的训练服务器很可能会使用不同版本的模型参数进行梯度计算，这种做法可能会伤害模型的精度，但它同时让不同训练服务器可以按照各自的运算速度推送和拉取参数，而无须等待同伴，因此避免了落后者对于整个集群性能的影响。</p>
<h3 id="_24">数据副本<a class="headerlink" href="#_24" title="Permanent link">&para;</a></h3>
<p>在参数服务器的实际部署中，人们往往需要解决数据热点问题。互联网数据往往符合幂律概率（Power-Law Distribution），这会导致部分参数在训练过程中被访问的次数会显著高于其他参数。例如，热门商品的嵌入项（Embedding Item）被训练服务器拉取的次数就会远远高于非热门商品。因此，存储了热门数据的参数服务器所承受的数据拉取和推送请求会远远高于其他参数服务器，因此形成数据热点，伤害了系统的可扩展性。</p>
<p>利用数据副本的另一个作用是增加系统的鲁棒性。当一个参数服务器出现故障，其所负责的参数将不可用，从而影响了整体系统的可用性。通过维护多个参数副本，当一个参数服务器故障时，系统可以将参数请求导向其他副本，同时在后台恢复故障的参数服务器，确保系统的可用性不受影响。</p>
<p>解决参数服务器故障和数据热点问题的常用技术是构建模型主从复制（Leader-Follower Replication）。一份参数在多个机器上拥有副本，并指定其中一个副本作为主副本（Leader Replica）。训练服务器的所有更新操作都向主副本写入，并同步至全部从副本（Follower Replica）。如何取得共识并确定哪一个副本是主副本是分布式系统领域一个经典问题，对该问题已经有了相当多的成熟算法，例如Paxos和Raft。此外，主副本上的更新如何复制到从副本上也是分布式系统领域的经典共识问题。通常系统设计者需要在可用性（Availability）和一致性（Consistency）之间做出取舍。如果参数服务器副本间采用强一致性（Strong Consistency）的复制协议（Replication Protocol），例如链式复制(Chain Replication)，则可能导致训练服务器的推送请求失败，即参数服务器不可用。反之，如果参数服务器采用弱一致性（Weak Consistency）的复制协议，则可能导致副本间存储的参数不一致。</p>
<h2 id="summary-and-expand">summary and expand<a class="headerlink" href="#summary-and-expand" title="Permanent link">&para;</a></h2>
<ul>
<li>大型机器学习模型的出现带来了对于算力和内存需求的快速增长，催生了分布式训练系统的出现。</li>
<li>分布式训练系统的设计往往遵循“分而治之”的设计思路。</li>
<li>利用分布式训练系统，人们可以显著提升训练性能，体现经济性，并且帮助防范硬件故障。</li>
<li>分布式训练系统可以通过数据并行增加设备来提升算力。</li>
<li>当单节点内存不足时，可以通过模型并行解决单设备内存不足。模型并行有两种实现方式：算子内并行和算子间并行。</li>
<li>大型模型并行系统容易出现设备使用气泡，而这种气泡可以通过流水线并行解决。</li>
<li>分布式训练系统往往运行在计算集群之中，集群网络无法提供充足的网络带宽来传输大量训练中生成的梯度。</li>
<li>为了提供海量的通信带宽，机器学习集群拥有异构的高性能网络，包括以太网、加速器高速互连技术NVLink和高带宽网络InfiniBand。</li>
<li>为了解决单节点瓶颈，可以使用AllReduce算法来分摊梯度聚合过程中产生的计算和通信操作，同时实现负载均衡。</li>
<li>参数服务器可以帮助实现灵活的梯度同步和异步训练，从而防范集群中可能出现的落后者服务器。</li>
<li>
<p>参数服务器常用数据副本技术解决数据热点问题和防范硬件故障。</p>
</li>
<li>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3377454">分布式机器学习系统综述</a></p>
</li>
<li><a href="https://arxiv.org/abs/1802.05799">利用集合通信支持并行训练的实践：Horovod</a></li>
<li><a href="https://arxiv.org/abs/1811.06965">流水线并行的实践：gPipe</a></li>
<li><a href="https://arxiv.org/abs/1706.02677">利用数据并行在大型数据集上高效训练深度学习模型</a></li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.top", "search.suggest", "search.highlight", "navigation.expand", "search.share"], "search": "../../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>