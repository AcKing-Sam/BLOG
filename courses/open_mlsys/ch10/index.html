
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../ch9/">
      
      
        <link rel="next" href="../ch11/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.18">
    
    
      
        <title>chapter 10 - AcKing's Ideas</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#-" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="AcKing&#39;s Ideas" class="md-header__button md-logo" aria-label="AcKing's Ideas" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AcKing's Ideas
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              chapter 10
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_3">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../ch2/" class="md-tabs__link md-tabs__link--active">
        courses
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../blogs/vector_db/something%20about%20vector%20db/" class="md-tabs__link">
        blogs
      </a>
    </li>
  

  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AcKing&#39;s Ideas" class="md-nav__button md-logo" aria-label="AcKing's Ideas" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AcKing's Ideas
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
          courses
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          courses
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_1_1" id="__nav_1_1_label" tabindex="0">
          open mlsys
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_1_1">
          <span class="md-nav__icon md-icon"></span>
          open mlsys
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch2/" class="md-nav__link">
        chapter 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch3/" class="md-nav__link">
        chapter 3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch4/" class="md-nav__link">
        chapter 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch6/" class="md-nav__link">
        chapter 6
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch7/" class="md-nav__link">
        chapter 7
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch8/" class="md-nav__link">
        chapter 8
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch9/" class="md-nav__link">
        chapter 9
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          chapter 10
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        chapter 10
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    intro
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    训练模型到推理模型的转换及优化
  </a>
  
    <nav class="md-nav" aria-label="训练模型到推理模型的转换及优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    模型转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    算子融合
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    算子替换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    算子重排
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    模型压缩
  </a>
  
    <nav class="md-nav" aria-label="模型压缩">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    量化
  </a>
  
    <nav class="md-nav" aria-label="量化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    量化感知训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    训练后量化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    模型稀疏
  </a>
  
    <nav class="md-nav" aria-label="模型稀疏">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    动机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    结构与非结构化稀疏
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    策略
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    知识蒸馏
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    模型推理
  </a>
  
    <nav class="md-nav" aria-label="模型推理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    前处理与后处理
  </a>
  
    <nav class="md-nav" aria-label="前处理与后处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    前处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    后处理
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    并行计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    算子优化
  </a>
  
    <nav class="md-nav" aria-label="算子优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    硬件指令优化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    算法优化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    模型的安全保护
  </a>
  
    <nav class="md-nav" aria-label="模型的安全保护">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intro_1" class="md-nav__link">
    intro
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_24" class="md-nav__link">
    模型混淆
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-expand" class="md-nav__link">
    summary and expand
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ch11/" class="md-nav__link">
        chapter 11
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          blogs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          blogs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          vector_db
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          vector_db
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/vector_db/something%20about%20vector%20db/" class="md-nav__link">
        something about vector db
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          storage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          storage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/storage/parquet/" class="md-nav__link">
        parquet
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
          linux
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          linux
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/linux/ld%E5%92%8Cld.so%E7%9A%84%E5%8C%BA%E5%88%AB/" class="md-nav__link">
        ld和ld.so的区别
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/linux/futex%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/" class="md-nav__link">
        futex锁原理及其应用
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    intro
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    训练模型到推理模型的转换及优化
  </a>
  
    <nav class="md-nav" aria-label="训练模型到推理模型的转换及优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    模型转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    算子融合
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    算子替换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    算子重排
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    模型压缩
  </a>
  
    <nav class="md-nav" aria-label="模型压缩">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    量化
  </a>
  
    <nav class="md-nav" aria-label="量化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    量化感知训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    训练后量化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    模型稀疏
  </a>
  
    <nav class="md-nav" aria-label="模型稀疏">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    动机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    结构与非结构化稀疏
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    策略
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    知识蒸馏
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    模型推理
  </a>
  
    <nav class="md-nav" aria-label="模型推理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    前处理与后处理
  </a>
  
    <nav class="md-nav" aria-label="前处理与后处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    前处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    后处理
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    并行计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_20" class="md-nav__link">
    算子优化
  </a>
  
    <nav class="md-nav" aria-label="算子优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_21" class="md-nav__link">
    硬件指令优化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_22" class="md-nav__link">
    算法优化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_23" class="md-nav__link">
    模型的安全保护
  </a>
  
    <nav class="md-nav" aria-label="模型的安全保护">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intro_1" class="md-nav__link">
    intro
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_24" class="md-nav__link">
    模型混淆
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-and-expand" class="md-nav__link">
    summary and expand
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="-">模型部署 -- 推理<a class="headerlink" href="#-" title="Permanent link">&para;</a></h1>
<p>模型部署是将训练好的模型部署到运行环境中进行推理的过程，模型部署的过程中需要解决训练模型到推理模型的转换，硬件资源对模型的限制，模型推理的时延、功耗、内存占用等指标对整个系统的影响以及模型的安全等一系列的问题。</p>
<h2 id="intro">intro<a class="headerlink" href="#intro" title="Permanent link">&para;</a></h2>
<p>模型完成训练后，需要将模型及参数持久化成文件，<strong>不同的训练框架导出的模型文件中存储的数据结构不同，这给模型的推理系统带来了不便</strong>。推理系统为了支持不同的训练框架的模型，需要<strong>将模型文件中的数据转换成统一的数据结构</strong>。此外，在训练模型转换成推理模型的过程中，需要进行一些如算子融合、常量折叠等模型的优化以<strong>提升推理的性能</strong>。</p>
<p>推理模型部署到不同的场景，需要<strong>满足不同的硬件设备的限制</strong>，例如，在具有强大算力的计算中心或数据中心的服务器上可以部署大规模的模型，而在边缘侧服务器、个人电脑以及智能手机上算力和内存则相对有限，部署的模型的规模就相应地要降低。在超低功耗的微控制器上，则只能部署非常简单的机器学习模型。此外，不同硬件对于不同数据类型（如float32、float16、bfloat16、int8等）的支持程度也不相同。为了满足这些硬件的限制，在有些场景下需要对训练好的模型进行压缩，降低模型的复杂度或者数据的精度，减少模型的参数，以适应硬件的限制。</p>
<p>模型部署到运行环境中执行推理，推理的时延、内存占用、功耗等是影响用户使用的关键因素，优化模型推理的方式有两种，一是<strong>设计专有的机器学习的芯片</strong>，相对于通用的计算芯片，这些专有芯片一般在能效比上具有很大的优势。二是<strong>通过软硬协同最大程度地发挥硬件的能力</strong>。对于第二种方式，以CPU为例，如何切分数据块以满足cache大小，如何对数据进行重排以便计算时可以连续访问，如何减少计算时的数据依赖以提升硬件流水线的并行，如何使用扩展指令集以提升计算性能，这些都需要针对不同的CPU架构进行设计和优化。</p>
<p>对于一个企业来讲，模型是属于重要的资产，因此，在模型部署到运行环境以后，保护模型的安全至关重要，业界有一些常见的方法：</p>
<ul>
<li><strong>算子融合</strong></li>
</ul>
<p>通过表达式简化、属性融合等方式将多个算子合并为一个算子的技术，融合可以降低模型的计算复杂度及模型的体积。</p>
<ul>
<li><strong>常量折叠</strong></li>
</ul>
<p>将符合条件的算子在离线阶段提前完成前向计算，从而降低模型的计算复杂度和模型的体积。常量折叠的条件是算子的所有输入在离线阶段均为常量。</p>
<ul>
<li><strong>模型压缩</strong></li>
</ul>
<p>通过量化、剪枝等手段减小模型体积以及计算复杂度的技术，可以分为需要重训的压缩技术和不需要重训的压缩技术两类。</p>
<ul>
<li><strong>数据排布</strong></li>
</ul>
<p>根据后端算子库支持程度和硬件限制，搜索网络中每层的最优数据排布格式，并进行数据重排或者插入数据重排算子，从而降低部署时的推理时延</p>
<ul>
<li><strong>模型混淆</strong></li>
</ul>
<p>对训练好的模型进行混淆操作，主要包括新增网络节点和分支、替换算子名的操作，攻击者即使窃取到混淆后的模型也不能理解原模型的结构。此外，混淆后的模型可以直接在部署环境中以混淆态执行，保证了模型在运行过程中的安全性。</p>
<h2 id="_1">训练模型到推理模型的转换及优化<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<h3 id="_2">模型转换<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>前面章节提到过，不同的训练框架，如Tensorflow、PyTorch、MindSpore、MXNet、CNTK等，都定义了自己的模型的数据结构，推理系统需要将它们转换到统一的一种数据结构上。开发神经网络交换协议（Open Neural Network Exchange，ONNX）正是为此目的而设计的。ONNX支持广泛的机器学习运算符集合，并提供了不同训练框架的转换器，例如TensorFlow模型到ONNX模型的转换器、PyTorch模型到ONNX模型的转换器等。 </p>
<p>模型转换本质上是将模型这种结构化的数据，从一种数据结构转换为另一种数据结构的过程。进行模型转换首先要分析两种数据结构的异同点，然后针对结构相同的数据做搬运；对于结构相似的数据做一一映射；对于结构差异较大的数据则需要根据其语义做合理的数据转换；更进一步如果两种数据结构上存在不兼容，则模型转换无法进行。ONNX的一个优势就在于其强大的表达能力，从而大多数业界框架的模型都能够转换到ONNX的模型上来而不存在不兼容的情况。</p>
<p>模型可以抽象为一种图，从而模型的数据结构可以解构为以下两个要点：</p>
<ul>
<li>模型拓扑连接：从图的角度来说，就是图的边；从AI模型的角度来说，就是AI模型中的数据流和控制流等。模型数据流和控制流的定义又可以引申出子图的表达形式、模型输入输出的表达形式、控制流结构的表达形式等。比如Tensorflow1.x中的控制流表达为一种有环图，通过Enter、Exit、Switch、LoopCond、NextIteration等算子来解决成环，而ONNX通过Loop，If等算子来表达控制流，从而避免引入了有环，所以在将Tensorflow1.x的控制流模型转化为ONNX模型时，需要将Tensorflow模型中的控制流图结构融合成ONNX的While或者If算子。</li>
<li>算子原型定义：从图的角度来说，就是图的顶点；从AI模型角度来说，就是AI模型中的数据处理节点或者控制流节点。算子原型包括但不限于算子类型、算子输入输出的定义、算子属性的定义等。比如Caffe的slice算子和ONNX的slice算子的语义其实是不一致的，Caffe的slice算子应该映射到ONNX的Split算子，所以在将Caffe模型转换成ONNX模型时，需要将Caffe的Slice算子映射到ONNX的Split算子。比如Tensorflow中的中的FusedBatchNorm算子在Caffe中找不到相同语义的算子，需要将Caffe的BatchNorm算子和Scale算子组合起来才能表达相同的语义。</li>
</ul>
<p>在完成模型转换之后，通常地，<strong>框架会将一些不依赖于输入的工作提前去完成</strong>。这些工作包括了如常量折叠、算子融合、算子替换、算子重排等一些优化手段。这些优化手段的概念在前面的章节其实已经提及到，比如在编译器前端阶段，通常也会做常量折叠；在编译器后端阶段，通常会根据后端的硬件支持程度，对算子进行融合和拆分。但是<strong>有些优化工作只有在部署阶段才能进行或者彻底进行。</strong></p>
<h3 id="_3">算子融合<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>将深度神经网络模型中的多个算子，按照一定的规则，合并成一个新的算子。通过算子融合，可以减少模型在线推理时的计算量、访存开销，从而降低推理时的时延和功耗。</p>
<p>算子融合带来的性能上的收益主要来自两个方面，一是通过融合，<strong>充分利用寄存器和缓存，避免多个算子运算时，数据在CPU和内存之间的存储和读取的耗时</strong>。二是通过融合，可以<strong>将一些计算量提前完成</strong>，避免了前向推理时的冗余计算或者循环冗余计算。</p>
<h3 id="_4">算子替换<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>将模型中某些算子替换计算逻辑一致但对于在线部署更友好的算子。算子替换的原理是通过合并同类项、提取公因式等数学方法，将算子的计算公式加以简化，并将简化后的计算公式映射到某类算子上。算子替换可以达到降低计算量、降低模型大小的效果。</p>
<p><img alt="image-20230720224606412" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307202246442.png" /></p>
<p>在Batchnorm算子被替换为Scale算子的前后，网络中的参数量、计算量都减少了，该算子替换策略可以优化模型部署时的功耗和性能。同理，<strong>该算子替换优化策略只能在部署阶段才能进行</strong>，因为一方面在部署阶段Batchnorm计算公式中被认为是常量的符号，在训练时是参数并非常量。另一方面该优化策略会降低模型的参数量，改变模型的结构，<strong>降低模型的表达能力，影响训练收敛时模型的准确率</strong>。</p>
<h3 id="_5">算子重排<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>将模型中算子的拓扑序按照某些规则进行重新排布，<strong>在不降低模型的推理精度的前提下，降低模型推理的计算量</strong>。常用的算子重排技术有针对于Slice算子、StrideSlice算子、Crop算子等裁切类算子的前移、Reshape算子和Transpose算子的重排、BinaryOp算子的重排等。</p>
<p><img alt="image-20230720224730844" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307202247873.png" /></p>
<p>如上图，Crop算子是从输入的特征图中裁取一部分作为输出，经过Crop算子后，特征图的大小就降低了。如果将这个裁切的过程前移，提前对特征图进行裁切，那么后续算子的计算量也会相应地减少，从而提高模型部署时的推理性能。Crop算子前移带来的性能提升跟Crop算子的参数有关。但是Crop算子一般只能沿着的element wise类算子前移。</p>
<p>通过前面的实验数据可以看到，通过推理前的模型优化，可以为推理的时延、功耗、内存占用带来极大的收益。</p>
<h2 id="_6">模型压缩<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<p>考虑到不同场景的硬件对模型的要求不同，比如部署在手机上，对于模型的大小比较敏感，一般在兆级别。因此，对于一些较大的模型，往往需要通过一些模型压缩的技术，使其能满足不同计算硬件的要求。</p>
<h3 id="_7">量化<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p>模型量化是指<strong>以较低的推理精度损失将连续取值（通常为float32或者大量可能的离散值）的浮点型权重近似为有限多个离散值（通常为int8）的过程</strong>，如下图，T是量化前的数据范围。通过以更少的位数表示浮点数据，模型量化可以减少模型尺寸，进而减少在推理时的内存消耗，并且在一些低精度运算较快的处理器上可以增加推理速度。</p>
<p><img alt="image-20230720225658310" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307202256331.png" /></p>
<p>计算机中不同数据类型的占用比特数及其表示的数据范围各不相同。可以根据实际业务需求将原模型量化成不同比特数的模型，一般<strong>深度神经网络的模型用单精度浮点数</strong>表示，如果<strong>能用有符号整数来近似原模型的参数，那么被量化的权重参数存储大小就可以降到原先的四分之一</strong>，用来量化的比特数越少，量化后的模型压缩率越高。工业界目前最常用的量化位数是8比特，低于8比特的量化被称为低比特量化。1比特是模型压缩的极限，可以将模型压缩为1/32，在推理时也可以使用高效的XNOR和BitCount位运算来提升推理速度。</p>
<p>另外，根据量化数据表示的原始数据范围是否均匀，还可以将量化方法分为<strong>线性量化和非线性量化</strong>。实际的深度神经网络的权重和激活值通常是不均匀的，因此理论上使用非线性量化导致的精度损失更小，但<strong>在实际推理中非线性量化的计算复杂度较高，通常使用线性量化</strong>。下面着重介绍线性量化的原理。</p>
<p>假设r表示量化前的浮点数，量化后的整数q可以表示为：</p>
<div class="arithmatex">\[q=clip(round(\frac{r}{s}+z),q_{min},q_{max})\]</div>
<p><span class="arithmatex">\(round(\cdot)\)</span>和<span class="arithmatex">\(clip(\cdot)\)</span>分别表示取整和截断操作，<span class="arithmatex">\(q_{min}\)</span>和<span class="arithmatex">\(q_{max}\)</span>是量化后的最小值和最大值。<span class="arithmatex">\(s\)</span>是数据量化的间隔，<span class="arithmatex">\(z\)</span>是表示数据偏移的偏置，<span class="arithmatex">\(z\)</span>为0的量化被称为<strong>对称（Symmetric）量化</strong>，不为0的量化称为非对称（Asymmetric）量化。对称量化可以避免量化算子在推理中计算z相关的部分，降低推理时的计算复杂度；非对称量化可以根据实际数据的分布确定最小值和最小值，可以更加充分的利用量化数据信息，使得量化导致的损失更低。</p>
<p>根据量化参数<span class="arithmatex">\(s\)</span>和<span class="arithmatex">\(z\)</span>的共享范围，量化方法可以分为<strong>逐层量化</strong>和<strong>逐通道量化</strong>：</p>
<ul>
<li>
<p>逐层量化以一层网络为量化单位，每层网络的一组量化参数</p>
</li>
<li>
<p>逐通道量化以一层网络的每个量化通道为单位，每个通道单独使用一组量化参数。</p>
</li>
</ul>
<p>逐通道量化由于量化粒度更细，能获得更高的量化精度，但计算也更复杂。</p>
<p>根据<strong>量化过程中是否需要训练</strong>，可以将模型量化分为量化感知训练（Quantization Aware Training, QAT）和训练后量化（Post Training Quantization, PTQ）两种。其中感知量化训练是指在模型训练过程中加入伪量化算子，通过训练时统计输入输出的数据范围可以<strong>提升量化后模型的精度</strong>，适用于对模型精度要求较高的场景；训练后量化指对训练后的模型直接量化，只<strong>需要少量校准数据</strong>，适用于追求高易用性和缺乏训练资源的场景。</p>
<h4 id="_8">量化感知训练<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<p>量化感知训练是在<strong>训练过程中模拟量化</strong>，利用<strong>伪量化算子</strong>将量化带来的精度损失计入训练误差，使得优化器能<strong>在训练过程中尽量减少量化误差</strong>，得到更高的模型精度。量化感知训练的具体流程如下：</p>
<ul>
<li>初始化：设置权重和激活值的范围<span class="arithmatex">\(q_{min}\)</span>和<span class="arithmatex">\(q_{max}\)</span>的初始值</li>
<li>构建模拟量化网络：在需要量化的权重和激活值后插入伪量化算子</li>
<li>量化训练：重复执行以下步骤直到网络收敛，计算量化网络层的权重和激活值的范围<span class="arithmatex">\(q_{min}\)</span>和<span class="arithmatex">\(q_{max}\)</span>，并<strong>根据该范围将量化损失</strong>带入到前向推理和后向参数更新的过程中</li>
<li>导出量化网络：获取<span class="arithmatex">\(q_{min}\)</span>和<span class="arithmatex">\(q_{max}\)</span>，并计算量化参数s和z；将量化参数代入量化公式中，转换网络中的权重为量化整数值；<strong>删除伪量化算子</strong>，在量化网络层前后分别插入量化和反量化算子</li>
</ul>
<h4 id="_9">训练后量化<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<h3 id="_10">模型稀疏<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<p>通过<strong>去除神经网络中部分组件</strong>（如权重、特征图、卷积核）降低网络的存储和计算代价，它和模型权重量化、权重共享、池化等方法一样，属于一种为达到降低模型计算复杂度的目标而引入的一种强归纳偏置。</p>
<h4 id="_11">动机<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<p>因为卷积神经网络中的卷积计算可以被看作输入数据和卷积核权重的加权线性组合，所以通常绝对值小的权重对输出数据具有相对较小的影响。对模型进行稀疏操作的合理性主要来源于两方面的假设：</p>
<ul>
<li>其一，针对<strong>权重参数</strong>来说，当前许多神经网络模型存在<strong>过参数化</strong>（Over-parameterized）的现象，动辄具有几千万甚至数亿规模的参数量。</li>
<li>其二，针对模型推理过程中生成的<strong>激活值特征图</strong>，对于许多检测、分类、分割等视觉任务来说激活值特征图中能利用的有效信息相对于整张图仅占较小的比例。</li>
</ul>
<p>根据以上描述按照模型稀疏性来源的不同，主要分为权重稀疏和激活值稀疏，它们的目的都是为了减少模型当中的冗余成分来达到降低计算量和模型存储的需求。具体来说，对模型进行稀疏就是根据模型的连接强弱程度（一般根据权重或激活的绝对值大小），对一些强度较弱的连接进行剪枝（将权重参数或激活值置为0）来达到模型稀疏并提高模型推理性能的目的。特别地，<strong>将模型权重或激活值张量中0值所占的比例称为模型稀疏度</strong>。一般而言，模型稀疏度越高带来的模型准确率下降越大，因此模型稀疏的目标是尽可能在提高模型稀疏度的同时保证模型准确率下降较小。</p>
<h4 id="_12">结构与非结构化稀疏<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<p>首先考虑权重稀疏，<strong>对于权重稀疏来说，按照稀疏模式的不同，主要分为结构化和非结构化稀疏</strong>。简单来讲，结构化稀疏就是在<strong>通道或者卷积核</strong>层面对模型进行剪枝。这种稀疏方式能够得到规则且规模更小的权重矩阵，因此比较适合CPU和GPU进行加速计算。但与此同时，结构化稀疏是一种粗粒度的稀疏方式，将会对模型的推理准确率造成较大的下降。</p>
<p>而非结构化稀疏，<strong>可以对权重张量中任意位置的权重进行裁剪</strong>，因此这种稀疏方式属于<strong>细粒度</strong>的稀疏。这种稀疏方式相对于结构化稀疏，造成的模型准确率下降较小。但是也正是因为这种<strong>不规则</strong>的稀疏方式，导致稀疏后的模型难以利用硬件获得较高的加速比。其背后原因主要有以下几点：</p>
<ul>
<li>不规则排布的模型权重矩阵会带来大量的控制流指令，比如由于大量0值的存在，会不可避免地引入大量if-else分支判断指令，因此会<strong>降低指令层面的并行度</strong></li>
<li>权重矩阵的不规则内存排布会造成线程发散和负载不均衡，而不同卷积核往往是利用多线程进行计算的，因此这也影响了线程层面的并行度</li>
<li>权重矩阵的不规则内存排布造成了较低的访存效率，因为它降低了数据的局部性以及缓存命中率</li>
</ul>
<p>为了解决以上非结构化稀疏带来的种种问题，近期出现的研究当中通过引入<strong>特定稀疏模式</strong>将结构化稀疏和非结构化稀疏结合了起来，从而一定程度上兼具结构化和非结构化稀疏的优点并克服了两者的缺点。</p>
<h4 id="_13">策略<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<p>明确了模型稀疏的对象之后，下一步需要确定模型稀疏的具体策略，具体来说，就是需要决定何时对模型进行稀疏以及如何对模型进行稀疏。目前最常见模型稀疏的一般流程为：<strong>预训练、剪枝、微调</strong>。具体而言，首先需要训练得到一个收敛的稠密模型，然后在此基础上进行稀疏和微调。选择在预训练之后进行稀疏动作的原因基于这样一个共识，即<strong>预训练模型的参数蕴含了学习到的知识，继承这些知识然后进行稀疏要比直接从初始化模型进行稀疏效果更好</strong>。除了基于预训练模型进行进一步修剪之外，<strong>训练和剪枝交替进行</strong>也是一种常用的策略。相比于一步修剪的方法，这种逐步的修剪方式，使得训练和剪枝紧密结合，可以更有效地发现冗余的卷积核，被广泛采用于现代神经网络剪枝方法中。</p>
<p>以下通过一个具体实例(Deep Compression([@han2015deep])） 来说明如何进行网络修剪：如 <a href="https://openmlsys.github.io/chapter_model_deployment/model_compression.html#ch08-fig-deepcomp">图10.3.2</a>所示，在去掉大部分的权值之后，深度卷积神经网络的精度将会低于其原始的精度。对剪枝后稀疏的神经网络进行微调，可以进一步提升压缩后网络的精度。剪枝后的模型可以进一步进行量化，使用更低比特的数据来表示权值；此外，结合霍夫曼（Huffman）编码可以进一步地降低深度神经网络的存储。</p>
<p><img alt="image-20230721074835449" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210748487.png" /></p>
<p>除了直接去除冗余的神经元之外，基于字典学习的方法也可以用来去掉深度卷积神经网络中无用的权值。通过学习一系列卷积核的基，可以把原始卷积核变换到系数域上并且它们稀疏。</p>
<h3 id="_14">知识蒸馏<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<p>知识蒸馏，也被称为教师-学生神经网络学习算法，已经受到业界越来越多的关注。大型深度网络在实践中往往会获得良好的性能，因为当考虑新数据时，过度参数化会提高泛化性能。在知识蒸馏中，小网络（学生网络）通常是由一个大网络（教师网络）监督，算法的关键问题是如何将教师网络的知识传授给学生网络。通常把一个全新的更深的更窄结构的深度神经网络当作学生神经网络，然后把一个预先训练好的神经网络模型当作教师神经网络。</p>
<p>Hinton等人([@Distill])首先提出了教师神经网络-学生神经网络学习框架，通过最小化两个神经网络之间的差异来学习一个更窄更深的神经网络。记教师神经网络为<span class="arithmatex">\(\mathcal{N}_{T}\)</span>，它的参数为<span class="arithmatex">\(\theta_T\)</span>，同时记学生神经网络为<span class="arithmatex">\(\mathcal{N}_{S}\)</span>，相应的参数为<span class="arithmatex">\(\theta_S\)</span>。一般而言，学生神经网络相较于教师神经网络具有更少的参数。</p>
<p>文献([@Distill])提出的知识蒸馏（knowledge distillation，KD）方法，同时令学生神经网络的分类结果接近真实标签并且令学生神经网络的分类结果接近于教师神经网络的分类结果，即，</p>
<p><img alt="image-20230721075109131" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210751155.png" /></p>
<p>其中，<span class="arithmatex">\(\mathcal{H}(\cdot,\cdot)\)</span>是交叉熵函数，<span class="arithmatex">\(o_S\)</span>和<span class="arithmatex">\(o_T\)</span>分别是学生网络和教师网络的输出，<span class="arithmatex">\(\mathbf{y}\)</span>是标签。公式中的第一项使得学生神经网络的分类结果接近预期的真实标签，而第二项的目的是提取教师神经网络中的有用信息并传递给学生神经网络，<span class="arithmatex">\(\lambda\)</span>是一个权值参数用来平衡两个目标函数。<span class="arithmatex">\(\tau(\cdot)\)</span>是一个软化（soften）函数，将网络输出变得更加平滑。</p>
<p>公式仅仅从教师神经网络分类器输出的数据中提取有价值的信息，并没有从其他中间层去将教师神经网络的信息进行挖掘。因此，Romero等人[@FitNet]）进一步地开发了一种学习轻型学生神经网络的方法，该算法可以<strong>从教师神经网络中任意的一层来传递有用的信息给学生神经网络</strong>。此外，事实上，并不是所有的输入数据对卷积神经网络的计算和完成后续的任务都是有用的。例如，在一张包含一个动物的图像中，对分类和识别结果比较重要的是动物所在的区域，而不是那些无用的背景信息。所以，有选择性地从教师神经网络的特征图中提取信息是一个更高效的方式。于是，Zagoruyko和Komodakis（[@attentionTS]）提出了一种<strong>基于感知（Attention）损失函数的学习方法来提升学生神经网络的性能</strong>，该方法在学习学生神经网络的过程中，引入了感知模块（Attention），选择性地将教师神经网络中的信息传递给学生神经网络，并帮助其进行训练。感知图用来表达输入图像不同位置对最终分类结果的重要性。感知模块从教师网络生成感知图，并迁移到学生网络。</p>
<p><img alt="image-20230721075158368" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210751397.png" /></p>
<p>知识蒸馏是一种有效的帮助小网络优化的方法，能够进一步和剪枝、量化等其他压缩方法结合，训练得到精度高、计算量小的高效模型。</p>
<h2 id="_15">模型推理<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h2>
<p>训练模型经过前面的转换、压缩等流程后，需要部署在计算硬件上进行推理。执行推理主要包含以下步骤：</p>
<ul>
<li>前处理：将原始数据处理成适合网络输入的数据。</li>
<li>执行推理：将离线转换得到的模型部署到设备上执行推理流程，根据输入数据计算得到输出数据。</li>
<li>后处理：模型的输出结果做进一步的加工处理，如筛选阈值。</li>
</ul>
<h3 id="_16">前处理与后处理<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h3>
<h4 id="_17">前处理<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h4>
<p>前处理主要完成数据预处理，在现实问题中，原始数据往往非常混乱，机器学习模型无法识别并从中提取信息。数据预处理的目的是将原始数据例如图片、语音、文本等，处理成适合网络输入的tensor数据，并消除其中无关的信息，恢复有用的真实信息，增强有关信息的可检测性，最大限度地简化数据，从而改进模型的特征抽取、图像分割、匹配和识别等可靠性。</p>
<p>常见的数据预处理手段有：</p>
<ul>
<li>特征编码：将描述特征的原始数据编码成数字，输入给机器学习模型，因为它们只能处理数字数据。常见的编码方法有：离散化、序号编码、One-hot编码，二进制编码等；</li>
<li>数据归一化：修改数据的值使其达到共同的标度但不改变它们之间的相关性，消除数据指标之间的量纲影响。常用的技术有：Min-Max归一化将数据缩放到给定范围，Z-score归一化使数据符合正态分布；</li>
<li>处理离群值: 离群值是与数据中的其他值保持一定距离的数据点，适当地排除离群值可以提升模型的准确性。</li>
</ul>
<h4 id="_18">后处理<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h4>
<p>通常，模型推理结束后，需要把推理的输出数据传递给用户完成后处理，常见的数据后处理手段有：</p>
<ul>
<li>连续数据离散化：模型实际用于预测离散数据，例如商品数量时，用回归模型预测得到的是连续值，需要四取五入、取上下限阈值等得到实际结果；</li>
<li>数据可视化：将数据图形化、表格化，便于找到数据之间的关系，来决定下一步的分析策略；</li>
<li>手动拉宽预测范围：回归模型往往预测不出很大或很小的值，结果都集中在中部区域。例如医院的化验数据，通常是要根据异常值诊断疾病。手动拉宽预测范围，将偏离正常范围的值乘一个系数，可以放大两侧的数据，得到更准确的预测结果。</li>
</ul>
<h3 id="_19">并行计算<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h3>
<p>为提升推理的性能，需要重复利用多核的能力，所以一般推理框架会引入多线程机制。主要的思路是将算子的输入数据进行切分，通过多线程去执行不同数据切片，实现算子并行计算，从而成倍提升算子计算性能。</p>
<p><img alt="image-20230721075636335" src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210756371.png" /></p>
<p>如图所示，对于矩阵乘可以按左矩阵的行进行切分，可以利用三个线程分别计算$A1 \times B <span class="arithmatex">\(，\)</span>A2 \times B <span class="arithmatex">\(，\)</span>A3 \times B $，实现矩阵乘多线程并行计算。</p>
<p>为方便算子并行计算，同时避免频繁创建销毁线程的开销，推理框架一般会使用<strong>线程池</strong>机制。业界有两种较为通用的做法：</p>
<ul>
<li>使用OpenMP编程接口：OpenMP（Open Multi-Processing，一套支持跨平台共享内存方式的多线程并发的编程API）提供如算子并行最常用的接口”parallel for”，实现for循环体的代码被多线程并行执行。</li>
<li>推理框架实现针对算子并行计算的线程池，相对OpenMP提供的接口会更有针对性，性能会更高，且更轻量。</li>
</ul>
<h3 id="_20">算子优化<a class="headerlink" href="#_20" title="Permanent link">&para;</a></h3>
<p>在部署AI模型时，用户通常期望模型执行训练或推理的时间尽可能地短，以获得更优越的性能。对于深度学习网络，框架调度的时间占比往往很小，性能的瓶颈就在算子的执行。下面从硬件指令和算法角度介绍一些算子优化的方法。</p>
<h4 id="_21">硬件指令优化<a class="headerlink" href="#_21" title="Permanent link">&para;</a></h4>
<p>常见的汇编层面优化</p>
<h4 id="_22">算法优化<a class="headerlink" href="#_22" title="Permanent link">&para;</a></h4>
<p>多数AI模型的推理时间主要耗费在卷积、矩阵乘算子的计算上，占到了整网百分之九十甚至更多的时间。本节介绍卷积算子算法方面的优化手段，可以应用到各种硬件设备上。</p>
<p>卷积的计算可以转换为两个矩阵相乘，在上面已经详细介绍了矩阵乘运算的优化。对于不同的硬件，确定合适的矩阵分块，优化数据访存与指令并行，可以最大限度的发挥硬件的算力，提升推理性能。</p>
<ol>
<li>
<p>Img2col</p>
</li>
<li>
<p>Winograd</p>
</li>
</ol>
<h2 id="_23">模型的安全保护<a class="headerlink" href="#_23" title="Permanent link">&para;</a></h2>
<h3 id="intro_1">intro<a class="headerlink" href="#intro_1" title="Permanent link">&para;</a></h3>
<p>模型的安全保护可以分为<strong>静态保护和动态保护</strong>两个方面。</p>
<p>静态保护指的是模型在传输和存储时的保护，目前业界普遍采用的是基于文件加密的模型保护方案，AI模型文件以密文形态传输和存储，执行推理前在内存中解密。在整个推理过程中，模型在内存中始终是明文的，存在被敌手从内存中转储的风险。</p>
<p>动态保护指的是模型在运行时的保护，目前业界已有的模型运行时保护方案主要有以下三个技术路线：</p>
<p>一是基于TEE（Trusted Execution Environment）的模型保护方案，TEE通常指的是通过可信硬件隔离出来的一个“安全区”，<strong>AI模型文件在非安全区加密存储和传输，在安全区中解密运行</strong>。该方案在CPU上的推理时延较小，但依赖特定可信硬件，有一定的部署难度。此外，受硬件资源约束，难以保护大规模深度模型，且目前仍无法有效支持异构硬件加速。</p>
<p>二是基于密态计算的保护方案，该方案基于密码学方法（如同态加密、多方安全计算等），保证模型在传输、存储和运行过程中始终保持密文状态。该方案不依赖特定硬件，但面临非常大的计算或通信开销问题，且无法保护模型结构信息。</p>
<p>三是基于混淆的模型保护方案，该方案主要通过对模型的计算逻辑进行加扰，使得敌手即使能获取到模型也无法理解。与前两种技术路线相比，该方案仅带来较小的性能开销，且精度损失很低，同时，不依赖特定硬件，可支持大模型的保护。下面将重点介绍基于混淆的模型保护技术。</p>
<h3 id="_24">模型混淆<a class="headerlink" href="#_24" title="Permanent link">&para;</a></h3>
<p>模型混淆技术可以自动混淆明文AI模型的计算逻辑，使得攻击者即使在传输和存储时获取到模型也无法理解；且支持模型混淆态执行，保证模型运行时的机密性。同时不影响模型原本的推理结果、仅带来较小的推理性能开销。模型混淆技术主要包含以下几个步骤：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/202307210806710.png" alt="image-20230721080621679" style="zoom:150%;" /></p>
<ol>
<li>解析模型并获取计算图</li>
</ol>
<p>对于一个训练好的模型，首先根据模型结构解析模型文件并获取模型计算逻辑的图表达（计算图）用于后续操作。获取的计算图包括节点标识、节点算子类型、节点参数权重以及网络结构等信息。</p>
<ol>
<li>对计算图的网络结构进行干扰</li>
</ol>
<p>通过图压缩和图增广等技术，对计算图中节点与节点之间的依赖关系进行加扰，达到隐藏模型真实计算逻辑的效果。其中，图压缩通过整图检查来匹配原网络中的关键子图结构，这些子图会压缩并替换为单个新的计算节点。对于压缩后的计算图，图增广通过在网络结构中加入新的输入/输出边，进一步隐藏节点间的真实依赖关系。新增的输入/输出边可以来自/指向图中现已有的节点，也可以来自/指向本步骤新增的混淆节点。</p>
<blockquote>
<p>加扰是指在计算图中添加扰动，来达到模型混淆的目的，常用的加扰手段有添加冗余的节点和边、融合部分子图等等。</p>
</blockquote>
<ol>
<li>对计算图的节点匿名化</li>
</ol>
<p>遍历步骤(2)处理后的计算图，<strong>筛选出需要保护的节点</strong>。对于图中的每个需要保护的节点，将节点标识、节点算子类型以及其他能够描述节点计算逻辑的属性替换为无语义信息的符号。<strong>对于节点标识匿名化，本步骤保证匿名化后的节点标识仍然是唯一的</strong>，以区分不同的节点。对于算子类型匿名化，为了避免大规模计算图匿名化导致的算子类型爆炸问题，可以将计算图中算子类型相同的节点划分为若干不相交的集合，同一个集合中节点的算子类型替换为相同的匿名符号。步骤(5)将保证节点匿名化后，模型仍然是可被识别和执行的。</p>
<ol>
<li>对计算图的参数权重加扰</li>
</ol>
<p>对于每个需要保护的权重，通过一个随机噪声和映射函数对权重进行加扰。每个权重加扰时可以使用不同的随机噪声和映射函数，步骤(6)将保证权重加扰不会影响模型执行结果的正确性。将经过步骤(2)(3)(4)处理后的计算图保存为模型文件供后续使用。</p>
<ol>
<li>算子接口变换</li>
</ol>
<p>步骤(5)(6)将对每个需要保护的算子类型进行算子形态变换，生成若干候选混淆算子。原算子与混淆算子之间是一对多的对应关系，候选混淆算子的数量等于步骤(3)划分的节点集合的数量。 本步骤根据步骤(2)(3)(4)的得到的匿名化算子类型、算子输入/输出关系等信息，对相应算子的接口进行变换。算子接口的变换方式<strong>包括但不局限于输入输出变换、接口名称变换</strong>。其中，输入输出变换通过修改原算子的输入输出数据，使得生成的混淆算子与原算子的接口形态不同。新增的输入输出数据包括步骤(2)图增广新增的节点间数据依赖和步骤(4)权重混淆引入的随机噪声。接口名称变换将原算子名称替换为步骤(3)生成的匿名化算子名称，保证节点匿名化后的模型仍然是可被识别和执行的，且算子的名称不会泄露其计算逻辑。</p>
<ol>
<li>算子实现变换</li>
</ol>
<p>对算子的代码实现进行变换。代码实现的变换方式包括但不局限于字符串加密、冗余代码等软件代码混淆技术，保证混淆算子与原算子实现语义相同的计算逻辑，但是难以阅读和理解。不同的算子可以采用不同代码混淆技术的组合进行代码变换。除代码等价变形之外，混淆算子还实现了一些额外的计算逻辑，如对于步骤(4)中参数被加扰的算子，混淆算子也实现了权重加扰的逆映射函数，用于在算子执行过程中动态消除噪声扰动，保证混淆后模型的计算结果与原模型一致。将生成的混淆算子保存为库文件供后续使用。</p>
<ol>
<li>部署模型和算子库</li>
</ol>
<p>将混淆态模型文件以及相应的混淆算子库文件部署到目标设备上。</p>
<ol>
<li>混淆模型加载</li>
</ol>
<p>根据模型结构解析混淆态模型文件并获取模型计算逻辑的图表达，即经过步骤(2)(3)(4)处理后得到的混淆计算图。</p>
<ol>
<li>计算图初始化</li>
</ol>
<p>对计算图进行初始化，生成执行任务序列。根据安全配置选项，若需要保护模型运行时安全，则直接对混淆计算图进行初始化，生成执行任务序列，序列中的每个计算单元对应一个混淆算子或原算子的执行。若仅需保护模型传输和存储时安全，则可先将内存中的混淆计算图恢复为原计算图，然后对原计算图进行初始化，生成执行任务序列，序列中的每个单元对应一个原算子的执行，这样可以进一步降低推理时的性能开销。</p>
<ol>
<li>推理任务执行</li>
</ol>
<p>根据AI应用程序输入的推理数据，遍历执行任务序列中的每个计算单元，得到推理结果。若当前计算单元对应的算子是混淆算子时，调用混淆算子库；否则，调用原算子库。</p>
<h2 id="summary-and-expand">summary and expand<a class="headerlink" href="#summary-and-expand" title="Permanent link">&para;</a></h2>
<ul>
<li>不同的模型部署场景下，通常对于模型大小、运行时内存占用、推理时延和推理功耗等指标有限制。</li>
<li>针对模型大小指标，通常在离线阶段通过模型压缩技术来优化，比如量化技术、剪枝技术、知识蒸馏技术等，除此之外，一部分模型优化技术，比如融合技术等，也有助于模型轻量化，不过其效果比较微弱。</li>
<li>针对运行时内存指标，主要有三方面的优化：优化模型大小、优化部署框架包大小以及优化运行时临时内存。模型大小的优化手段在上一点中已经说明；部署框架包大小主要通过精简框架代码、框架代码模块化等方式来优化。运行时临时内存主要通过内存池实现内存之间的复用来优化。</li>
<li>针对模型的推理时延指标，主要有两方面的优化，一方面是离线时通过模型优化技术和模型压缩技术尽可能降低模型推理所需的计算量；另一方面是通过加大推理的并行力度和优化算子实现来充分挖掘硬件的计算潜力。值得注意的是，除了考虑计算量和算力，推理时的访存开销也是一个重要的影响因素。</li>
<li>针对模型的推理功耗，主要的优化思路是降低模型的计算量，这与针对模型推理时延的优化手段有重合之处，可以参考离线的模型优化技术和模型压缩技术。</li>
<li>
<p>本章除了介绍优化模型部署的各方面指标的优化技术以外，还介绍了安全部署相关的技术，如模型混淆、模型加密等。部署安全一方面可以保护企业的重要资产，另一方面可以防止黑客通过篡改模型从而入侵攻击部署环境。</p>
</li>
<li>
<p>Google量化白皮书 <a href="https://arxiv.org/abs/1806.08342">量化</a></p>
</li>
<li>诺亚高精度剪枝算法 <a href="https://arxiv.org/abs/2010.10732">剪枝</a></li>
<li>针对多核处理器的自动图并行调度框架 <a href="https://proceedings.mlsys.org/paper/2021/file/a5e00132373a7031000fd987a3c9f87b-Paper.pdf">性能优化</a></li>
<li>诺亚量子启发的低比特量化算法 <a href="https://arxiv.org/abs/2009.08695">量化</a></li>
<li>诺亚GhostNet极简骨干网络 <a href="https://arxiv.org/abs/1911.11907">网络结构替换</a></li>
<li>诺亚加法神经网络 [网络结构替换](https://arxiv.org/abs/1912.13200）</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.top", "search.suggest", "search.highlight", "navigation.expand", "search.share"], "search": "../../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>